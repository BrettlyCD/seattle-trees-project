{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas:\n",
    "\n",
    "Forecast into future (change age at obs)\n",
    "Forecast rainy next 5 years (change age at obs and prcp)\n",
    "Forecast change in temp (change age at obs and temp)\n",
    "Idetify if a specific species it at risk\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Modeling\n",
    "\n",
    "## 5.0 Introduction\n",
    "\n",
    "Now that we've got our model established, I want to do some exploring. First, I will load in my full testing and training data and fit the model to the full range of data. I will unfortunately need to do the full imputing, SMOTE (to address imbalanced classes), scaling, and encoding to keep things consistent. \n",
    "\\\n",
    "\\\n",
    "Once we have that full sampling prepped, we can fit on it then predict using our *ENTIRE DATAFRAME*. That's a lot of data so let's hope it goes well. From there we can do some mapping and modeling. Should be fun!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Load and process\n",
    "\n",
    "### 5.2.0 Load Data\n",
    "Load in the raw X and y data we saved at the end of our last step. This is our full 20k sample records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 10) (20000, 1)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('../data/data_outputs/X_full_sample.csv')\n",
    "y = pd.read_csv('../data/data_outputs/y_full_sample.csv')\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy X and y to new dataframes\n",
    "X_full = X.reset_index(drop=True)\n",
    "y_full = y.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Process Data for Fitting Model\n",
    "\n",
    "#### 5.2.1.0 Initialized Imputers, Scalers, and Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "ss_scaler = StandardScaler()\n",
    "pow_trans = PowerTransformer()\n",
    "ohe1 = OneHotEncoder(handle_unknown='ignore', sparse_output=False) #one for our common_name column\n",
    "ohe2 = OneHotEncoder(handle_unknown='ignore', sparse_output=False) #one for our native column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1.1 Create and Apply Name Grouping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_categories(df, col, n_limit):\n",
    "    \"\"\" Store categories in df[col] with counts less than the specified n and overwrite the corresponding values in the df with 'Other' \"\"\"\n",
    "    groups = df[col]\n",
    "    group_counts = groups.value_counts()\n",
    "    mask = groups.isin(group_counts[group_counts<n_limit].index)\n",
    "    df.loc[mask, col] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run group categories on common_name\n",
    "group_categories(X_full, 'common_name', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Red maple                         696\n",
       "Apple/crabapple                   566\n",
       "Purpleleaf plum variety           565\n",
       "Norway maple                      542\n",
       "(smooth) japanese maple           518\n",
       "                                 ... \n",
       "American sycamore                   3\n",
       "Eugene`s (carolina) poplar          3\n",
       "Rancho pear                         3\n",
       "American dream swamp white oak      3\n",
       "Turkestan mountain ash              3\n",
       "Name: common_name, Length: 428, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View Value Counts\n",
    "X_full['common_name'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1.2 Imput Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep for SMOTE, impute missing and group categorical values\n",
    "#impute missing values\n",
    "X_full['age_at_obs'] = num_imputer.fit_transform(X_full[['age_at_obs']])\n",
    "X_full['common_name'] = cat_imputer.fit_transform(X_full[['common_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1.3 SMOTE X Data to Address Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition_index\n",
       "4.0                55.325\n",
       "3.0                24.135\n",
       "5.0                13.510\n",
       "2.0                 5.420\n",
       "1.0                 1.610\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View our balance of classes\n",
    "y_full.value_counts() / y_full.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use smote\n",
    "sm = SMOTENC(random_state=42, categorical_features=[0,2])\n",
    "X_smote, y_smote = sm.fit_resample(X_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition_index\n",
      "1.0                20.0\n",
      "2.0                20.0\n",
      "3.0                20.0\n",
      "4.0                20.0\n",
      "5.0                20.0\n",
      "dtype: float64\n",
      "(55325, 10)\n"
     ]
    }
   ],
   "source": [
    "#view new resampled distribution\n",
    "print(y_smote.value_counts() / y_smote.shape[0] * 100)\n",
    "\n",
    "print(X_smote.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1.4 Scale Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaler\n",
    "X_smote[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','prcp_mm_normal']] = ss_scaler.fit_transform(X_smote[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','prcp_mm_normal']])\n",
    "\n",
    "#Power Transformer\n",
    "X_smote[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']] = pow_trans.fit_transform(X_smote[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_name</th>\n",
       "      <th>diameter_breast_height_CM</th>\n",
       "      <th>native</th>\n",
       "      <th>age_at_obs</th>\n",
       "      <th>adj_reports</th>\n",
       "      <th>norm_prcp_mm_total</th>\n",
       "      <th>norm_snow_mm_total</th>\n",
       "      <th>distance_between</th>\n",
       "      <th>temp_avg_normal</th>\n",
       "      <th>prcp_mm_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norwegian sunset maple</td>\n",
       "      <td>1.001482</td>\n",
       "      <td>introduced</td>\n",
       "      <td>0.351816</td>\n",
       "      <td>0.293119</td>\n",
       "      <td>-1.626061</td>\n",
       "      <td>0.576894</td>\n",
       "      <td>-0.768214</td>\n",
       "      <td>1.283766</td>\n",
       "      <td>-1.212323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red maple</td>\n",
       "      <td>1.273147</td>\n",
       "      <td>introduced</td>\n",
       "      <td>0.628887</td>\n",
       "      <td>0.717425</td>\n",
       "      <td>-0.707730</td>\n",
       "      <td>-0.994286</td>\n",
       "      <td>-1.327058</td>\n",
       "      <td>-0.784582</td>\n",
       "      <td>0.770351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paperbark maple</td>\n",
       "      <td>-1.156072</td>\n",
       "      <td>introduced</td>\n",
       "      <td>-1.551102</td>\n",
       "      <td>-1.389654</td>\n",
       "      <td>-0.097643</td>\n",
       "      <td>-0.994286</td>\n",
       "      <td>0.911242</td>\n",
       "      <td>-0.784582</td>\n",
       "      <td>0.770351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cleveland norway maple</td>\n",
       "      <td>1.188115</td>\n",
       "      <td>introduced</td>\n",
       "      <td>-0.407969</td>\n",
       "      <td>0.868185</td>\n",
       "      <td>-1.212498</td>\n",
       "      <td>-0.994286</td>\n",
       "      <td>-0.628992</td>\n",
       "      <td>1.283766</td>\n",
       "      <td>-1.212323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leonard messel lobner magnolia</td>\n",
       "      <td>-0.740522</td>\n",
       "      <td>no_info</td>\n",
       "      <td>-2.178112</td>\n",
       "      <td>0.918547</td>\n",
       "      <td>0.795283</td>\n",
       "      <td>1.517000</td>\n",
       "      <td>0.496152</td>\n",
       "      <td>1.283766</td>\n",
       "      <td>-1.212323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      common_name  diameter_breast_height_CM      native  \\\n",
       "0          Norwegian sunset maple                   1.001482  introduced   \n",
       "1                       Red maple                   1.273147  introduced   \n",
       "2                 Paperbark maple                  -1.156072  introduced   \n",
       "3          Cleveland norway maple                   1.188115  introduced   \n",
       "4  Leonard messel lobner magnolia                  -0.740522     no_info   \n",
       "\n",
       "   age_at_obs  adj_reports  norm_prcp_mm_total  norm_snow_mm_total  \\\n",
       "0    0.351816     0.293119           -1.626061            0.576894   \n",
       "1    0.628887     0.717425           -0.707730           -0.994286   \n",
       "2   -1.551102    -1.389654           -0.097643           -0.994286   \n",
       "3   -0.407969     0.868185           -1.212498           -0.994286   \n",
       "4   -2.178112     0.918547            0.795283            1.517000   \n",
       "\n",
       "   distance_between  temp_avg_normal  prcp_mm_normal  \n",
       "0         -0.768214         1.283766       -1.212323  \n",
       "1         -1.327058        -0.784582        0.770351  \n",
       "2          0.911242        -0.784582        0.770351  \n",
       "3         -0.628992         1.283766       -1.212323  \n",
       "4          0.496152         1.283766       -1.212323  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smote.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1.5 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index to create clean join after encoding\n",
    "X_smote.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#transform our common_name field with ohe and put into dataframe\n",
    "X_name = ohe1.fit_transform(X_smote[['common_name']])\n",
    "name_df = pd.DataFrame(X_name, columns=ohe1.categories_[0]) #indexing 0 here to grab only the column names\n",
    "\n",
    "#transform our native field with ohe and put into dataframe\n",
    "X_native = ohe2.fit_transform(X_smote[['native']])\n",
    "native_df = pd.DataFrame(X_native, columns=ohe2.categories_[0])\n",
    "\n",
    "#concat these two dataframes back into X_res and X_test and create new dataframe, dropping original categorical fields\n",
    "X_smote_scaled_coded = pd.concat([X_smote, name_df, native_df], axis=1)\n",
    "\n",
    "#drop original categorical fields\n",
    "X_smote_scaled_coded.drop(columns=['common_name', 'native'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55325, 10) (55325, 429) (55325, 3)\n",
      "(55325, 440)\n"
     ]
    }
   ],
   "source": [
    "#review shape of created variables\n",
    "print(X_smote.shape,name_df.shape,native_df.shape)\n",
    "print(X_smote_scaled_coded.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Fit Model on Our Full Data Sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
