{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Pre-Processing & Training\n",
    "\n",
    "In our last step, we did some joining of our data based on latitude and longitude and explored our features. In this next step we will prepare for modeling by tuning our features, and maybe even adding a feature or two. We will have some challenges with finding the right mix and tuning of features when our initial correlation review didn't show much to work with. Maybe more challenging will be how to deal with our fairly imbalanced data.\n",
    "\n",
    "## 3.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RepeatedStratifiedKFold, cross_val_score, KFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC #using SMOTENC because it accepts a mix of numeric and categorical values\n",
    "\n",
    "#imports for saving model\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planted_date</th>\n",
       "      <th>most_recent_observation</th>\n",
       "      <th>common_name</th>\n",
       "      <th>long_trees</th>\n",
       "      <th>lat_trees</th>\n",
       "      <th>diameter_breast_height_CM</th>\n",
       "      <th>condition</th>\n",
       "      <th>native</th>\n",
       "      <th>age_at_obs</th>\n",
       "      <th>condition_index</th>\n",
       "      <th>...</th>\n",
       "      <th>adj_reports</th>\n",
       "      <th>norm_prcp_mm_total</th>\n",
       "      <th>norm_snow_mm_total</th>\n",
       "      <th>distance_between</th>\n",
       "      <th>temp_avg_normal</th>\n",
       "      <th>temp_min_normal</th>\n",
       "      <th>temp_max_normal</th>\n",
       "      <th>temp_range_normal</th>\n",
       "      <th>prcp_mm_normal</th>\n",
       "      <th>tree_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991-07-22</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>(european) white birch</td>\n",
       "      <td>-122.282080</td>\n",
       "      <td>47.635207</td>\n",
       "      <td>40.64</td>\n",
       "      <td>excellent</td>\n",
       "      <td>introduced</td>\n",
       "      <td>27.765115</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947927</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-07-30</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>Kwanzan flowering cherry</td>\n",
       "      <td>-122.318952</td>\n",
       "      <td>47.649141</td>\n",
       "      <td>5.08</td>\n",
       "      <td>fair</td>\n",
       "      <td>no_info</td>\n",
       "      <td>27.743212</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.367105</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1991-07-25</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>Japanese snowbell tree</td>\n",
       "      <td>-122.299891</td>\n",
       "      <td>47.637863</td>\n",
       "      <td>2.54</td>\n",
       "      <td>excellent</td>\n",
       "      <td>introduced</td>\n",
       "      <td>27.756901</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.145690</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  planted_date most_recent_observation               common_name  long_trees  \\\n",
       "0   1991-07-22              2019-04-27    (european) white birch -122.282080   \n",
       "1   1991-07-30              2019-04-27  Kwanzan flowering cherry -122.318952   \n",
       "2   1991-07-25              2019-04-27    Japanese snowbell tree -122.299891   \n",
       "\n",
       "   lat_trees  diameter_breast_height_CM  condition      native  age_at_obs  \\\n",
       "0  47.635207                      40.64  excellent  introduced   27.765115   \n",
       "1  47.649141                       5.08       fair     no_info   27.743212   \n",
       "2  47.637863                       2.54  excellent  introduced   27.756901   \n",
       "\n",
       "   condition_index  ... adj_reports norm_prcp_mm_total norm_snow_mm_total  \\\n",
       "0              5.0  ...         237        1071.925479                0.0   \n",
       "1              3.0  ...         237        1071.925479                0.0   \n",
       "2              5.0  ...         237        1071.925479                0.0   \n",
       "\n",
       "   distance_between  temp_avg_normal  temp_min_normal  temp_max_normal  \\\n",
       "0          0.947927             53.2             45.7             60.8   \n",
       "1          3.367105             53.2             45.7             60.8   \n",
       "2          1.145690             53.2             45.7             60.8   \n",
       "\n",
       "   temp_range_normal  prcp_mm_normal  tree_id  \n",
       "0               15.0         960.628        1  \n",
       "1               15.0         960.628        2  \n",
       "2               15.0         960.628        3  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_df = pd.read_csv('../data/data_outputs/seattle_trees_explored.csv')\n",
    "\n",
    "trees_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prep DF for Train-Test split\n",
    "\n",
    "We'll take another look at the columns, as we can likely drop the additional reference info from our climate 'prcp' data source. And then we'll split our dependent and independent variables.\n",
    "\n",
    "### 3.2.0 Drop Unecessary Columns\n",
    "\n",
    "We'll drop the reference cols from climate data like I mentioned above, but also the 'condition' column because it is duplicative of our target feature. Our tree_id because it has no more use. And our date cols, because we have the calculated age feature that will be our variable related to dates/ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158004 entries, 0 to 158003\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   planted_date               155133 non-null  object \n",
      " 1   most_recent_observation    157999 non-null  object \n",
      " 2   common_name                157332 non-null  object \n",
      " 3   long_trees                 158004 non-null  float64\n",
      " 4   lat_trees                  158004 non-null  float64\n",
      " 5   diameter_breast_height_CM  158004 non-null  float64\n",
      " 6   condition                  158004 non-null  object \n",
      " 7   native                     158004 non-null  object \n",
      " 8   age_at_obs                 155128 non-null  float64\n",
      " 9   condition_index            158004 non-null  float64\n",
      " 10  nearest_station            158004 non-null  object \n",
      " 11  station_id                 158004 non-null  object \n",
      " 12  station_name               158004 non-null  object \n",
      " 13  lat_prcp                   158004 non-null  float64\n",
      " 14  long_prcp                  158004 non-null  float64\n",
      " 15  adj_reports                158004 non-null  int64  \n",
      " 16  norm_prcp_mm_total         158004 non-null  float64\n",
      " 17  norm_snow_mm_total         158004 non-null  float64\n",
      " 18  distance_between           158004 non-null  float64\n",
      " 19  temp_avg_normal            158004 non-null  float64\n",
      " 20  temp_min_normal            158004 non-null  float64\n",
      " 21  temp_max_normal            158004 non-null  float64\n",
      " 22  temp_range_normal          158004 non-null  float64\n",
      " 23  prcp_mm_normal             158004 non-null  float64\n",
      " 24  tree_id                    158004 non-null  int64  \n",
      "dtypes: float64(15), int64(2), object(8)\n",
      "memory usage: 30.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#View our columns\n",
    "trees_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop our columns that are reference from climate dataset and the original condition column (which we used to create our target index feature)\n",
    "trees_df = trees_df.drop(columns=['nearest_station', 'station_id',\n",
    "       'station_name', 'lat_prcp', 'long_prcp', 'condition', 'planted_date','most_recent_observation','tree_id','long_trees','lat_trees','temp_min_normal','temp_max_normal','temp_range_normal']) #also drop some of the climate normals fields since they don't add anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['common_name', 'diameter_breast_height_CM', 'native', 'age_at_obs',\n",
       "       'condition_index', 'adj_reports', 'norm_prcp_mm_total',\n",
       "       'norm_snow_mm_total', 'distance_between', 'temp_avg_normal',\n",
       "       'prcp_mm_normal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Sample Dataset to Make Size More Manageable\n",
    "One model may not be too crazy, but running a gridsearch CV on hundreds of thousands of rows may be a bit much for me. I'll start with a sample of 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_sample = trees_df.sample(n=10000, replace=False, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Split Dependent and Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X = trees_sample.drop(columns=['condition_index'])\n",
    "y = trees_sample['condition_index']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train-Test Split\n",
    "We'll use an 80:20 split here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10) (8000,) (2000, 10) (2000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Impute Missing Values\n",
    "\n",
    "We will use the median for our age at observation and mode for common name.\n",
    "\n",
    "### 3.4.0 Establish Simple Imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name                   43\n",
       "diameter_breast_height_CM      0\n",
       "native                         0\n",
       "age_at_obs                   155\n",
       "adj_reports                    0\n",
       "norm_prcp_mm_total             0\n",
       "norm_snow_mm_total             0\n",
       "distance_between               0\n",
       "temp_avg_normal                0\n",
       "prcp_mm_normal                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Impute Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and transform\n",
    "X_train['age_at_obs'] = num_imputer.fit_transform(X_train[['age_at_obs']])\n",
    "X_train['common_name'] = cat_imputer.fit_transform(X_train[['common_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name                  0\n",
       "diameter_breast_height_CM    0\n",
       "native                       0\n",
       "age_at_obs                   0\n",
       "adj_reports                  0\n",
       "norm_prcp_mm_total           0\n",
       "norm_snow_mm_total           0\n",
       "distance_between             0\n",
       "temp_avg_normal              0\n",
       "prcp_mm_normal               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate no missing values\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Simple Feature Engineering\n",
    "\n",
    "Before running a first test model, I'll do some basic feature engineering. After testing on a single model we'll move into doing further tuning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Categorical Encoding\n",
    "\n",
    "We'll need to encode our categorical features. And for our tree names, we'll likely need to group together some of the less frequent options so we don't overwhelm our model with a crazy number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['common_name', 'native'], dtype='object')"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns = trees_df.select_dtypes(include='object').columns\n",
    "\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Red maple                  287\n",
       "Purpleleaf plum variety    237\n",
       "Norway maple               216\n",
       "Apple/crabapple            215\n",
       "(smooth) japanese maple    202\n",
       "                          ... \n",
       "Snow gum                     1\n",
       "Cascade snow cherry          1\n",
       "Javelin pear                 1\n",
       "Oceanspray                   1\n",
       "Almond tree                  1\n",
       "Name: common_name, Length: 485, dtype: int64"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view value_counts of common_name field\n",
    "X_train['common_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                       common_name\n",
       "(arnold) tulip tree         1              1\n",
       "Pacific yew                 1              1\n",
       "Patmore green ash           1              1\n",
       "Paw paw                     1              1\n",
       "Plane/sycamore              2              1\n",
       "                                          ..\n",
       "Empire ash                  2              1\n",
       "English elm                 1              1\n",
       "Eucalyptus/gum              2              1\n",
       "Eugene`s (carolina) poplar  2              1\n",
       "Zelkova                     2              1\n",
       "Length: 182, dtype: int64"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many of the 485 categories have less than 10 records?\n",
    "\n",
    "vc = pd.DataFrame(X_train['common_name'].value_counts())\n",
    "\n",
    "vc.reset_index(inplace=True)\n",
    "\n",
    "vc[vc['common_name'] < 3].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "introduced             116127\n",
       "no_info                 32616\n",
       "naturally_occurring      9261\n",
       "Name: native, dtype: int64"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view value_counts of common_name field\n",
    "trees_df['native'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1.0 Convert common_name Field to Group Names with < 100 Occurences\n",
    "\n",
    "This will limit the number of columns we have. We won't do thes ame for the native field. We'll do it by defining a function that can be utilized later as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_categories(df, col, n_limit):\n",
    "    \"\"\" Store categories in df[col] with counts less than the specified n and overwrite the corresponding values in the df with 'Other' \"\"\"\n",
    "    groups = df[col]\n",
    "    group_counts = groups.value_counts()\n",
    "    mask = groups.isin(group_counts[group_counts<n_limit].index)\n",
    "    df.loc[mask, col] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Red maple                  287\n",
       "Other                      257\n",
       "Purpleleaf plum variety    237\n",
       "Norway maple               216\n",
       "Apple/crabapple            215\n",
       "                          ... \n",
       "Japanese crabapple           3\n",
       "Princeton elm                3\n",
       "Stewartia                    3\n",
       "Autumn glory hawthorn        3\n",
       "Juniper                      3\n",
       "Name: common_name, Length: 304, dtype: int64"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use our group categories feature on our X_train set\n",
    "group_categories(X_train, 'common_name', 3)\n",
    "\n",
    "X_train['common_name'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 First Model\n",
    "\n",
    "Now that we've done some basic tuning, let's do some transforming with the feature engineering tools we fit and run a logistic regression model to see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_name</th>\n",
       "      <th>diameter_breast_height_CM</th>\n",
       "      <th>native</th>\n",
       "      <th>age_at_obs</th>\n",
       "      <th>adj_reports</th>\n",
       "      <th>norm_prcp_mm_total</th>\n",
       "      <th>norm_snow_mm_total</th>\n",
       "      <th>distance_between</th>\n",
       "      <th>temp_avg_normal</th>\n",
       "      <th>prcp_mm_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85168</th>\n",
       "      <td>Common serviceberry</td>\n",
       "      <td>7.62</td>\n",
       "      <td>introduced</td>\n",
       "      <td>3.652368</td>\n",
       "      <td>217</td>\n",
       "      <td>849.190323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.243978</td>\n",
       "      <td>53.2</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85613</th>\n",
       "      <td>missing</td>\n",
       "      <td>7.62</td>\n",
       "      <td>no_info</td>\n",
       "      <td>11.641581</td>\n",
       "      <td>217</td>\n",
       "      <td>849.190323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317906</td>\n",
       "      <td>53.2</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11471</th>\n",
       "      <td>Other</td>\n",
       "      <td>12.70</td>\n",
       "      <td>introduced</td>\n",
       "      <td>19.154397</td>\n",
       "      <td>347</td>\n",
       "      <td>1138.700000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.330051</td>\n",
       "      <td>53.8</td>\n",
       "      <td>926.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57576</th>\n",
       "      <td>American hornbeam</td>\n",
       "      <td>5.08</td>\n",
       "      <td>introduced</td>\n",
       "      <td>2.965153</td>\n",
       "      <td>224</td>\n",
       "      <td>1045.880645</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.434896</td>\n",
       "      <td>53.2</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130978</th>\n",
       "      <td>Pacific sunset maple</td>\n",
       "      <td>27.94</td>\n",
       "      <td>introduced</td>\n",
       "      <td>18.929889</td>\n",
       "      <td>19</td>\n",
       "      <td>1183.835484</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.953287</td>\n",
       "      <td>53.2</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 common_name  diameter_breast_height_CM      native  \\\n",
       "85168    Common serviceberry                       7.62  introduced   \n",
       "85613                missing                       7.62     no_info   \n",
       "11471                  Other                      12.70  introduced   \n",
       "57576      American hornbeam                       5.08  introduced   \n",
       "130978  Pacific sunset maple                      27.94  introduced   \n",
       "\n",
       "        age_at_obs  adj_reports  norm_prcp_mm_total  norm_snow_mm_total  \\\n",
       "85168     3.652368          217          849.190323                 0.0   \n",
       "85613    11.641581          217          849.190323                 0.0   \n",
       "11471    19.154397          347         1138.700000                35.0   \n",
       "57576     2.965153          224         1045.880645                13.0   \n",
       "130978   18.929889           19         1183.835484                 5.0   \n",
       "\n",
       "        distance_between  temp_avg_normal  prcp_mm_normal  \n",
       "85168           1.243978             53.2         960.628  \n",
       "85613           0.317906             53.2         960.628  \n",
       "11471           1.330051             53.8         926.846  \n",
       "57576           3.434896             53.2         960.628  \n",
       "130978          1.953287             53.2         960.628  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Scalers and Transforms\n",
    "\n",
    "ss_scaler = StandardScaler()\n",
    "pow_trans = PowerTransformer()\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding some steps here -> My encoding is either encoding all values or keeping the specified ones. I want to fit and transform my categorical and then load them back into the main dataframe for a complete dataframe with scaled and encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_scaler, pow_trans, ohe\n",
    "#transform with our ss_scaler\n",
    "X_train[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','prcp_mm_normal']] = ss_scaler.fit_transform(X_train[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','prcp_mm_normal']])\n",
    "\n",
    "#transform with our pow_trans\n",
    "X_train[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']] = pow_trans.fit_transform(X_train[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']])\n",
    "\n",
    "#reset index to create clean join after encoding\n",
    "X_train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform with our categorical columns and create dataframes\n",
    "X_train_cn = ohe.fit_transform(X_train[['common_name']])\n",
    "cn_df = pd.DataFrame(X_train_cn, columns=ohe.categories_[0]) #indexing 0 here to grab only the column names\n",
    "\n",
    "X_train_nat = ohe.fit_transform(X_train[['native']])\n",
    "nat_df = pd.DataFrame(X_train_nat, columns=ohe.categories_[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10)\n",
      "(8000, 304)\n",
      "(8000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(cn_df.shape)\n",
    "print(nat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat these two dataframes back into X_train and create new dataframe, dropping original categorical fields\n",
    "X_train_transformed = pd.concat([X_train, cn_df, nat_df], axis=1,)\n",
    "\n",
    "#drop original categorical fields\n",
    "X_train_transformed.drop(columns=['common_name', 'native'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 315)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.58\n"
     ]
    }
   ],
   "source": [
    "#Initiate and run logistic regression model\n",
    "\n",
    "logreg = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1)\n",
    "\n",
    "logreg.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(f'Accuracy on training data: {accuracy_score(logreg.predict(X_train_transformed), y_train):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       120\n",
      "         2.0       0.00      0.00      0.00       421\n",
      "         3.0       0.48      0.19      0.27      1921\n",
      "         4.0       0.59      0.94      0.73      4410\n",
      "         5.0       0.56      0.15      0.24      1128\n",
      "\n",
      "    accuracy                           0.58      8000\n",
      "   macro avg       0.33      0.25      0.25      8000\n",
      "weighted avg       0.52      0.58      0.50      8000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, logreg.predict(X_train_transformed)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decent accuracy, but it's because we're only predicting the most common values, which isn't suprising based on our imbalanced data. Let's work on addressing the imbalanced data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Work on Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 4410, 4410, 4410, 4410, 4410])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use SMOTE to resample and balance our dataset\n",
    "sm = SMOTENC(random_state=42, categorical_features=[0,2])\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "np.bincount(y_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.0 Re-Run Model Using 'SMOTED' Data\n",
    "\n",
    "#### 3.7.0.0 Start by Re-Scaling and Encdoing and then Loading back to a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_scaler, pow_trans, ohe\n",
    "#transform with our ss_scaler\n",
    "X_res[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','prcp_mm_normal']] = ss_scaler.fit_transform(X_res[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','prcp_mm_normal']])\n",
    "\n",
    "#transform with our pow_trans\n",
    "X_res[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']] = pow_trans.fit_transform(X_res[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']])\n",
    "\n",
    "#reset index to create clean join after encoding\n",
    "X_res.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform with our categorical columns and create dataframes\n",
    "X_res_cn = ohe.fit_transform(X_res[['common_name']])\n",
    "cn_res_df = pd.DataFrame(X_res_cn, columns=ohe.categories_[0]) #indexing 0 here to grab only the column names\n",
    "\n",
    "X_res_nat = ohe.fit_transform(X_res[['native']])\n",
    "nat_res_df = pd.DataFrame(X_res_nat, columns=ohe.categories_[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22050, 10)\n",
      "(22050, 304)\n",
      "(22050, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_res.shape)\n",
    "print(cn_res_df.shape)\n",
    "print(nat_res_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050, 315)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat these two dataframes back into X_train and create new dataframe, dropping original categorical fields\n",
    "X_res_transformed = pd.concat([X_res, cn_res_df, nat_res_df], axis=1,)\n",
    "\n",
    "#drop original categorical fields\n",
    "X_res_transformed.drop(columns=['common_name', 'native'], inplace=True)\n",
    "\n",
    "X_res_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, max_iter=500, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, max_iter=500, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, max_iter=500, solver='liblinear')"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initiate and run logistic regression model\n",
    "\n",
    "logreg = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1)\n",
    "\n",
    "logreg.fit(X_res_transformed, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.49\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.57      0.80      0.67      4410\n",
      "         2.0       0.45      0.44      0.44      4410\n",
      "         3.0       0.41      0.27      0.33      4410\n",
      "         4.0       0.48      0.41      0.44      4410\n",
      "         5.0       0.48      0.55      0.51      4410\n",
      "\n",
      "    accuracy                           0.49     22050\n",
      "   macro avg       0.48      0.49      0.48     22050\n",
      "weighted avg       0.48      0.49      0.48     22050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on training data: {accuracy_score(logreg.predict(X_res_transformed), y_res):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_res, logreg.predict(X_res_transformed)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "Less overall accuracy, but this is a step in the right direction as our recall looks much better. With basically no hyperparamter tuning, we still have work to do.\n",
    "\n",
    "## 3.8 Tuning\n",
    "\n",
    "I tested out the pretty simple tuning but I'd actually like to do some different scaling depending on the feature in preperation for hyperparamter tuning. I'll do that now on my resampled dataframe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.1 Try Another Approach On Imbalanced Data\n",
    "\n",
    "Rather than using my resamples SMOTE dataframe, I want to try applying all of the other transformations the same, but this time on my initial 10,000 record sample using RepeatedStratifiedKFold cross validation.\n",
    "\n",
    "#### 3.8.1.0 Apply Transformation to Initial Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this time I'm going to just call fit_transform on my earlier imputers and scalers\n",
    "\n",
    "X_train['age_at_obs'] = num_imputer.fit_transform(X_train[['age_at_obs']])\n",
    "X_train['common_name'] = cat_imputer.fit_transform(X_train[['common_name']])\n",
    "X_train[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']] = pow_trans.fit_transform(X_train[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']])\n",
    "X_train[['age_at_obs','norm_prcp_mm_total']] = ss_scaler.fit_transform(X_train[['age_at_obs','norm_prcp_mm_total']])\n",
    "X_train_transformed = ohe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8000x10726 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 64380 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1.1 Define Our Cross-Validation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1.2 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model with our best params so far\n",
    "logreg2 = LogisticRegression(random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1.3 Fit and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.89\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.20      0.33       120\n",
      "         2.0       1.00      0.31      0.48       421\n",
      "         3.0       0.93      0.87      0.90      1921\n",
      "         4.0       0.87      0.99      0.92      4410\n",
      "         5.0       0.94      0.83      0.88      1128\n",
      "\n",
      "    accuracy                           0.89      8000\n",
      "   macro avg       0.95      0.64      0.70      8000\n",
      "weighted avg       0.90      0.89      0.88      8000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg2.fit(X_train_transformed, y_train)\n",
    "print(f'Accuracy on training data: {accuracy_score(logreg2.predict(X_train_transformed), y_train):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, logreg2.predict(X_train_transformed)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "Using the StratifiedKFold didn't give us as good of results as using SMOTE, so we'll go back to that method going forward."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Try Different Models\n",
    "\n",
    "The best we got with logistic regression was 47% accuracy. That leaves much to be desired, so let's try something other than this type of model. We'll use our X_res_scaled and y_res for consistency.\n",
    "\n",
    "### 3.9.0 Test Set Performance Comparison\n",
    "\n",
    "If we do some simple default setting comparison between KNeighbors, Decision Trees, and Random Forest, it could give us a good sense of where to focus our time going forward."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.0.0 Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list types of models to run\n",
    "models = {'logreg': LogisticRegression(),\n",
    "          'knn': KNeighborsClassifier(),\n",
    "          'dec_tree': DecisionTreeClassifier(),\n",
    "          'rand_for': RandomForestClassifier(),\n",
    "          'ada': AdaBoostClassifier(),\n",
    "          'gradient': GradientBoostingClassifier()\n",
    "          }\n",
    "\n",
    "#create blank list to store results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/brettly/Sboard/projects/seattle-trees-project/notebooks/03_preproc_and_train.ipynb Cell 60\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brettly/Sboard/projects/seattle-trees-project/notebooks/03_preproc_and_train.ipynb#Y142sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brettly/Sboard/projects/seattle-trees-project/notebooks/03_preproc_and_train.ipynb#Y142sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     kf \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m#using KFold this time rather than setting up a whole GridSearch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brettly/Sboard/projects/seattle-trees-project/notebooks/03_preproc_and_train.ipynb#Y142sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     cv_results \u001b[39m=\u001b[39m cross_val_score(model, X_res_scaled, y_res, cv\u001b[39m=\u001b[39;49mkf)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brettly/Sboard/projects/seattle-trees-project/notebooks/03_preproc_and_train.ipynb#Y142sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     results\u001b[39m.\u001b[39mappend(cv_results)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/joblib/parallel.py:1048\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1048\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1049\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[1;32m    537\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[1;32m    539\u001b[0m     X,\n\u001b[1;32m    540\u001b[0m     y,\n\u001b[1;32m    541\u001b[0m     raw_predictions,\n\u001b[1;32m    542\u001b[0m     sample_weight,\n\u001b[1;32m    543\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[1;32m    544\u001b[0m     X_val,\n\u001b[1;32m    545\u001b[0m     y_val,\n\u001b[1;32m    546\u001b[0m     sample_weight_val,\n\u001b[1;32m    547\u001b[0m     begin_at_stage,\n\u001b[1;32m    548\u001b[0m     monitor,\n\u001b[1;32m    549\u001b[0m )\n\u001b[1;32m    551\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    608\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[1;32m    609\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    610\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    611\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    612\u001b[0m     )\n\u001b[1;32m    614\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 615\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[1;32m    616\u001b[0m     i,\n\u001b[1;32m    617\u001b[0m     X,\n\u001b[1;32m    618\u001b[0m     y,\n\u001b[1;32m    619\u001b[0m     raw_predictions,\n\u001b[1;32m    620\u001b[0m     sample_weight,\n\u001b[1;32m    621\u001b[0m     sample_mask,\n\u001b[1;32m    622\u001b[0m     random_state,\n\u001b[1;32m    623\u001b[0m     X_csc,\n\u001b[1;32m    624\u001b[0m     X_csr,\n\u001b[1;32m    625\u001b[0m )\n\u001b[1;32m    627\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    254\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    256\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[0;32m--> 257\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    259\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[1;32m    260\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    261\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[1;32m    262\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[1;32m    270\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/tree/_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1219\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1248\u001b[0m         X,\n\u001b[1;32m   1249\u001b[0m         y,\n\u001b[1;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Loop through models, score and save\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True) #using KFold this time rather than setting up a whole GridSearch\n",
    "    cv_results = cross_val_score(model, X_res_scaled, y_res, cv=kf)\n",
    "    results.append(cv_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.0.1 Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "Our Random Forest looks to be just slightly better than a decision tree model as is already better than our logistic regression model without any tuning. Let's explore this model futher.\n",
    "\n",
    "### 3.9.1 Random Forest Classifier\n",
    "\n",
    "This time I'll use RandomizedSearchCV to tune params. Source: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "#### 3.9.1.0 Create Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['log2', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "#list out our different params\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] #number of trees in the forest\n",
    "max_features = ['log2','sqrt'] #number of features to consider at each split\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)] #max levels in tree\n",
    "min_samples_split = [2,5,10] #min samples required to split a node\n",
    "min_samples_leaf = [1,2,4] #min samples at each leaf node\n",
    "bootstrap = [True, False] #sampling method using bootsrap or not\n",
    "\n",
    "#Create random grid\n",
    "rand_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(rand_grid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1.1 One Hot Encode\n",
    "\n",
    "I want to try this without any scaling, but I will do my onehotencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name                  category\n",
       "diameter_breast_height_CM     float64\n",
       "native                       category\n",
       "age_at_obs                    float64\n",
       "adj_reports                   float64\n",
       "norm_prcp_mm_total            float64\n",
       "norm_snow_mm_total            float64\n",
       "distance_between              float64\n",
       "temp_avg_normal               float64\n",
       "temp_min_normal               float64\n",
       "temp_max_normal               float64\n",
       "temp_range_normal             float64\n",
       "prcp_mm_normal                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update to categorical dtypes\n",
    "X_res['common_name'] = X_res.common_name.astype('category')\n",
    "X_res['native'] = X_res.native.astype('category')\n",
    "\n",
    "X_res.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish ohe\n",
    "ohe = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "#fit and transform\n",
    "x_res_encoded = ohe.fit_transform(X_res[['common_name','native']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1.1 Fit with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=   5.3s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=   5.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.3s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   6.9s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   6.8s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   6.9s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   6.9s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400; total time=   8.9s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400; total time=   9.4s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400; total time=   9.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400; total time=   9.2s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400; total time=  10.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1200; total time=   4.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1200; total time=   4.3s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1200; total time=   4.3s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1200; total time=   4.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1200; total time=   4.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   8.3s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   8.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   8.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   8.5s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   8.4s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.2s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.1s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.1s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.1s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.1s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=   7.3s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=   7.5s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   3.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.2s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.2s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1800; total time=  12.0s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1800; total time=  12.3s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1800; total time=  12.1s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1800; total time=  12.2s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1800; total time=  12.1s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  12.1s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  12.2s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  12.4s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  12.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  12.6s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=  12.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=  12.8s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=  12.9s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=  13.2s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=  13.1s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=   3.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=   3.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=   3.6s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   4.6s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   4.7s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   4.8s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   4.8s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   4.8s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.2s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.2s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.3s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.6s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.3s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1400; total time=   5.6s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1400; total time=   5.7s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1400; total time=   5.7s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1400; total time=   5.7s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1400; total time=   5.7s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  12.4s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  12.5s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  12.5s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   2.2s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   2.3s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   2.3s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   2.3s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   2.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.8s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.4s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.4s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.5s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   5.9s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.0s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.0s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.7s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.7s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1200; total time=   7.3s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1200; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1200; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1200; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1200; total time=   7.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.3s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.1s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.0s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.0s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.2s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   2.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   2.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  11.4s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  11.4s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  11.5s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  11.5s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  11.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   2.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   2.9s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time=   4.0s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time=   4.1s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.4s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.2s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=   1.8s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=   1.8s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=   1.9s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=   1.9s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=   1.9s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time=   3.5s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800; total time=  10.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800; total time=  10.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800; total time=  10.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800; total time=  10.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800; total time=  10.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=   7.9s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   5.3s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  10.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  11.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  11.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  11.2s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  11.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=  11.2s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=  11.2s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=  11.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=  11.6s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=  11.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110],\n",
       "                                        'max_features': ['log2', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "#Random Search Cross-Val\n",
    "rf_rand = RandomizedSearchCV(estimator=rf, param_distributions=rand_grid, n_iter=50, cv=5, verbose=2, random_state=42) #sample 50 param settings, 5 fold cross-val, computation time display\n",
    "\n",
    "#fit the model on the non-scaled data\n",
    "rf_rand.fit(x_res_encoded, y_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1.2 Review Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 110,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rand.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1.3 Fit Model Using Best Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.42\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.50      0.68      0.58      4410\n",
      "         2.0       0.35      0.50      0.41      4410\n",
      "         3.0       0.35      0.23      0.28      4410\n",
      "         4.0       0.42      0.30      0.35      4410\n",
      "         5.0       0.45      0.39      0.42      4410\n",
      "\n",
      "    accuracy                           0.42     22050\n",
      "   macro avg       0.41      0.42      0.41     22050\n",
      "weighted avg       0.41      0.42      0.41     22050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run a fit with those params and view more details scoring\n",
    "\n",
    "#setup model\n",
    "rf_tuned = RandomForestClassifier(n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features='sqrt', max_depth=110, bootstrap=True)\n",
    "\n",
    "#fit model\n",
    "rf_tuned.fit(x_res_encoded, y_res)\n",
    "\n",
    "#review scores\n",
    "print(f'Accuracy on training data: {accuracy_score(rf_tuned.predict(x_res_encoded), y_res):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_res, rf_tuned.predict(x_res_encoded)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "This actually didn't get us much more than our inital model. Either way, it is the best we've gotten so far so let's try it out on the test set.\n",
    "\n",
    "#### 3.9.1.4 Scale and Test for Better Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-transform to be able to appropriately fit my ohe\n",
    "X_res['age_at_obs'] = num_imputer.fit_transform(X_res[['age_at_obs']])\n",
    "X_res['common_name'] = cat_imputer.fit_transform(X_res[['common_name']])\n",
    "X_res[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']] = pow_trans.fit_transform(X_res[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']])\n",
    "X_res[['age_at_obs','norm_prcp_mm_total']] = ss_scaler.fit_transform(X_res[['age_at_obs','norm_prcp_mm_total']])\n",
    "\n",
    "#re-fit ohe\n",
    "X_res_scaled = ohe.fit_transform(X_res[['common_name','native']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.42\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.50      0.68      0.58      4410\n",
      "         2.0       0.35      0.50      0.41      4410\n",
      "         3.0       0.35      0.23      0.28      4410\n",
      "         4.0       0.42      0.30      0.35      4410\n",
      "         5.0       0.45      0.39      0.42      4410\n",
      "\n",
      "    accuracy                           0.42     22050\n",
      "   macro avg       0.41      0.42      0.41     22050\n",
      "weighted avg       0.41      0.42      0.41     22050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check Results\n",
    "\n",
    "#fit model\n",
    "rf_tuned.fit(X_res_scaled, y_res)\n",
    "\n",
    "#review scores\n",
    "print(f'Accuracy on training data: {accuracy_score(rf_tuned.predict(X_res_scaled), y_res):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_res, rf_tuned.predict(X_res_scaled)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't add anything, which makes sense because RF is pretty resilient to different scaling. Let's move forward sticking with only the imputing and categorical encoding.\n",
    "\n",
    "### 3.9.2 Evaluate RF Model on Test Set\n",
    "\n",
    "The first thing we'll need to do is process our X_test using the same steps we did on our X_train.\n",
    "\n",
    "#### 3.9.2.0 Pre-Processing X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name                  category\n",
       "diameter_breast_height_CM     float64\n",
       "native                       category\n",
       "age_at_obs                    float64\n",
       "adj_reports                     int64\n",
       "norm_prcp_mm_total            float64\n",
       "norm_snow_mm_total            float64\n",
       "distance_between              float64\n",
       "temp_avg_normal               float64\n",
       "temp_min_normal               float64\n",
       "temp_max_normal               float64\n",
       "temp_range_normal             float64\n",
       "prcp_mm_normal                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Update object to categorical\n",
    "X_test['common_name'] = X_test.common_name.astype('category')\n",
    "X_test['native'] = X_test.native.astype('category')\n",
    "\n",
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0, 1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#refit imputers\n",
    "num_imputer.fit(X_res[['age_at_obs']])\n",
    "cat_imputer.fit(X_res[['common_name']])\n",
    "\n",
    "#refit ohe on x_res\n",
    "ohe.fit(X_res[['common_name','native']])\n",
    "\n",
    "#Apply transformations from the steps we fitted earlier in the model\n",
    "X_test['age_at_obs'] = num_imputer.transform(X_test[['age_at_obs']])\n",
    "X_test['common_name'] = cat_imputer.transform(X_test[['common_name']])\n",
    "\n",
    "X_test_transformed = ohe.transform(X_test[['common_name','native']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x308 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1707 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.48\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.03      0.05      0.04        39\n",
      "         2.0       0.16      0.15      0.16        93\n",
      "         3.0       0.37      0.29      0.33       503\n",
      "         4.0       0.59      0.69      0.63      1091\n",
      "         5.0       0.27      0.17      0.21       274\n",
      "\n",
      "    accuracy                           0.48      2000\n",
      "   macro avg       0.28      0.27      0.27      2000\n",
      "weighted avg       0.46      0.48      0.46      2000\n",
      "\n",
      "----------------------------------------\n",
      "[[  2   7   3  25   2]\n",
      " [  2  14  29  46   2]\n",
      " [ 10  23 145 291  34]\n",
      " [ 41  32 176 753  89]\n",
      " [  9  11  36 171  47]]\n"
     ]
    }
   ],
   "source": [
    "#refit on unscaled data\n",
    "rf_tuned.fit(x_res_encoded, y_res)\n",
    "\n",
    "#predict\n",
    "y_pred = rf_tuned.predict(X_test_transformed)\n",
    "\n",
    "print(f'Accuracy on training data: {accuracy_score(y_pred, y_test):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('----------------------------------------')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "\\\n",
    "As we'd expect from a lower training result, our test results aren't all that much better than a random guess if my math is correct. I will go ahead and export the model, but will continue to research and round back to see if there are any useful features that could be added or engineered to achieve better results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Save Model\n",
    "\n",
    "### 4.0.0 Define Saving Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions for saving model provided by Springboard Guided Capstone\n",
    "def _save_file(data, fpath):\n",
    "    valid_ftypes = ['.csv', '.pkl']\n",
    "    \n",
    "    assert (fpath[-4:] in valid_ftypes), \"Invalid file type.  Use '.csv' or '.pkl'\"\n",
    "\n",
    "    # Figure out what kind of file we're dealing with by name\n",
    "    if fpath[-3:] == 'csv':\n",
    "        data.to_csv(fpath, index=False)\n",
    "    elif fpath[-3:] == 'pkl':\n",
    "        with open(fpath, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "def save_file(data, fname, dname):\n",
    "    \"\"\"Save a datafile (data) to a specific location (dname) and filename (fname)\n",
    "    \n",
    "    Currently valid formats are limited to CSV or PKL.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(dname):\n",
    "        os.mkdir(dname)\n",
    "        print(f'Directory {dname} was created.')\n",
    "        \n",
    "    fpath = os.path.join(dname, fname)\n",
    "    \n",
    "    \n",
    "    if os.path.exists(fpath):\n",
    "        print(\"A file already exists with this name.\\n\")\n",
    "\n",
    "        yesno = None\n",
    "        while yesno != \"Y\" and yesno != \"N\":\n",
    "            yesno = input('Do you want to overwrite? (Y/N)').strip()[0].capitalize()\n",
    "            if yesno == \"Y\":\n",
    "                print(f'Writing file.  \"{fpath}\"')\n",
    "                _save_file(data, fpath)\n",
    "                break  # Not required\n",
    "            elif yesno == \"N\":\n",
    "                print('\\nPlease re-run this cell with a new filename.')\n",
    "                break  # Not required\n",
    "            else:\n",
    "                print('\\nUnknown input, please enter \"Y\" or \"N\".')\n",
    "\n",
    "    else:  # path does not exist, ok to save the file\n",
    "        print(f'Writing file.  \"{fpath}\"')\n",
    "        _save_file(data, fpath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.1 Identify Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf_rand.best_estimator_\n",
    "rf_model.version = '1.0'\n",
    "rf_model.pandas_version = pd.__version__\n",
    "rf_model.numpy_version = np.__version__\n",
    "rf_model.sklearn_version = sklearn_version\n",
    "rf_model.X_columns = [col for col in X_train.columns]\n",
    "rf_model.build_datetime = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file.  \"../models/trees_rf_model.pkl\"\n"
     ]
    }
   ],
   "source": [
    "#Save the model to the new /models folder\n",
    "modelpath = '../models/'\n",
    "save_file(rf_model, 'trees_rf_model.pkl', modelpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
