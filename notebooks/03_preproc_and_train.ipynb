{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Pre-Processing & Training\n",
    "\n",
    "In our last step, we did some joining of our data based on latitude and longitude and explored our features. In this next step we will prepare for modeling by tuning our features, and maybe even adding a feature or two. We will have some challenges with finding the right mix and tuning of features when our initial correlation review didn't show much to work with. Maybe more challenging will be how to deal with our fairly imbalanced data.\n",
    "\n",
    "## 3.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planted_date</th>\n",
       "      <th>most_recent_observation</th>\n",
       "      <th>common_name</th>\n",
       "      <th>long_trees</th>\n",
       "      <th>lat_trees</th>\n",
       "      <th>diameter_breast_height_CM</th>\n",
       "      <th>condition</th>\n",
       "      <th>native</th>\n",
       "      <th>age_at_obs</th>\n",
       "      <th>condition_index</th>\n",
       "      <th>nearest_station</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>lat_prcp</th>\n",
       "      <th>long_prcp</th>\n",
       "      <th>adj_reports</th>\n",
       "      <th>norm_prcp_mm_total</th>\n",
       "      <th>norm_snow_mm_total</th>\n",
       "      <th>distance_between</th>\n",
       "      <th>tree_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991-07-22</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>(european) white birch</td>\n",
       "      <td>-122.282080</td>\n",
       "      <td>47.635207</td>\n",
       "      <td>40.64</td>\n",
       "      <td>excellent</td>\n",
       "      <td>introduced</td>\n",
       "      <td>27.765115</td>\n",
       "      <td>5.0</td>\n",
       "      <td>WA-KG-266</td>\n",
       "      <td>WA-KG-266</td>\n",
       "      <td>Seattle 2.9 ENE</td>\n",
       "      <td>47.630883</td>\n",
       "      <td>-122.290286</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-07-30</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>Kwanzan flowering cherry</td>\n",
       "      <td>-122.318952</td>\n",
       "      <td>47.649141</td>\n",
       "      <td>5.08</td>\n",
       "      <td>fair</td>\n",
       "      <td>no_info</td>\n",
       "      <td>27.743212</td>\n",
       "      <td>3.0</td>\n",
       "      <td>WA-KG-266</td>\n",
       "      <td>WA-KG-266</td>\n",
       "      <td>Seattle 2.9 ENE</td>\n",
       "      <td>47.630883</td>\n",
       "      <td>-122.290286</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.367105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1991-07-25</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>Japanese snowbell tree</td>\n",
       "      <td>-122.299891</td>\n",
       "      <td>47.637863</td>\n",
       "      <td>2.54</td>\n",
       "      <td>excellent</td>\n",
       "      <td>introduced</td>\n",
       "      <td>27.756901</td>\n",
       "      <td>5.0</td>\n",
       "      <td>WA-KG-266</td>\n",
       "      <td>WA-KG-266</td>\n",
       "      <td>Seattle 2.9 ENE</td>\n",
       "      <td>47.630883</td>\n",
       "      <td>-122.290286</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.145690</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  planted_date most_recent_observation               common_name  long_trees  \\\n",
       "0   1991-07-22              2019-04-27    (european) white birch -122.282080   \n",
       "1   1991-07-30              2019-04-27  Kwanzan flowering cherry -122.318952   \n",
       "2   1991-07-25              2019-04-27    Japanese snowbell tree -122.299891   \n",
       "\n",
       "   lat_trees  diameter_breast_height_CM  condition      native  age_at_obs  \\\n",
       "0  47.635207                      40.64  excellent  introduced   27.765115   \n",
       "1  47.649141                       5.08       fair     no_info   27.743212   \n",
       "2  47.637863                       2.54  excellent  introduced   27.756901   \n",
       "\n",
       "   condition_index nearest_station station_id     station_name   lat_prcp  \\\n",
       "0              5.0       WA-KG-266  WA-KG-266  Seattle 2.9 ENE  47.630883   \n",
       "1              3.0       WA-KG-266  WA-KG-266  Seattle 2.9 ENE  47.630883   \n",
       "2              5.0       WA-KG-266  WA-KG-266  Seattle 2.9 ENE  47.630883   \n",
       "\n",
       "    long_prcp  adj_reports  norm_prcp_mm_total  norm_snow_mm_total  \\\n",
       "0 -122.290286          237         1071.925479                 0.0   \n",
       "1 -122.290286          237         1071.925479                 0.0   \n",
       "2 -122.290286          237         1071.925479                 0.0   \n",
       "\n",
       "   distance_between  tree_id  \n",
       "0          0.947927        1  \n",
       "1          3.367105        2  \n",
       "2          1.145690        3  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_df = pd.read_csv('../data/data_outputs/seattle_trees_explored.csv')\n",
    "\n",
    "trees_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prep DF for Train-Test split\n",
    "\n",
    "We'll take another look at the columns, as we can likely drop the additional reference info from our climate 'prcp' data source. And then we'll split our dependent and independent variables.\n",
    "\n",
    "### 3.2.0 Drop Unecessary Columns\n",
    "\n",
    "We'll drop the reference cols from climate data like I mentioned above, but also the 'condition' column because it is duplicative of our target feature. And our date cols, because we have the calculated age feature that will be our variable related to dates/ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158004 entries, 0 to 158003\n",
      "Data columns (total 20 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   planted_date               155133 non-null  object \n",
      " 1   most_recent_observation    157999 non-null  object \n",
      " 2   common_name                157332 non-null  object \n",
      " 3   long_trees                 158004 non-null  float64\n",
      " 4   lat_trees                  158004 non-null  float64\n",
      " 5   diameter_breast_height_CM  158004 non-null  float64\n",
      " 6   condition                  158004 non-null  object \n",
      " 7   native                     158004 non-null  object \n",
      " 8   age_at_obs                 155128 non-null  float64\n",
      " 9   condition_index            158004 non-null  float64\n",
      " 10  nearest_station            158004 non-null  object \n",
      " 11  station_id                 158004 non-null  object \n",
      " 12  station_name               158004 non-null  object \n",
      " 13  lat_prcp                   158004 non-null  float64\n",
      " 14  long_prcp                  158004 non-null  float64\n",
      " 15  adj_reports                158004 non-null  int64  \n",
      " 16  norm_prcp_mm_total         158004 non-null  float64\n",
      " 17  norm_snow_mm_total         158004 non-null  float64\n",
      " 18  distance_between           158004 non-null  float64\n",
      " 19  tree_id                    158004 non-null  int64  \n",
      "dtypes: float64(10), int64(2), object(8)\n",
      "memory usage: 24.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#View our columns\n",
    "trees_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop our columns that are reference from climate dataset and the original condition column (which we used to create our target index feature)\n",
    "trees_df = trees_df.drop(columns=['nearest_station', 'station_id',\n",
    "       'station_name', 'lat_prcp', 'long_prcp', 'condition', 'planted_date','most_recent_observation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['common_name', 'long_trees', 'lat_trees', 'diameter_breast_height_CM',\n",
       "       'native', 'age_at_obs', 'condition_index', 'adj_reports',\n",
       "       'norm_prcp_mm_total', 'norm_snow_mm_total', 'distance_between',\n",
       "       'tree_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Split Dependent and Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X = trees_df.drop(columns=['condition_index'])\n",
    "y = trees_df[['condition_index']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train-Test Split\n",
    "We'll use an 80:20 split here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126403, 11) (126403, 1) (31601, 11) (31601, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Impute Missing Values\n",
    "\n",
    "We will use the median for our age at observation and mode for common name.\n",
    "\n",
    "### 3.4.0 Calculate Modes and Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_median_age = X_train['age_at_obs'].median()\n",
    "X_mode_name = X_train['common_name'].mode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Impute Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute planted_date\n",
    "X_train['age_at_obs'] = X_train['age_at_obs'].fillna(X_median_age)\n",
    "X_train['common_name'] = X_train['common_name'].fillna(X_mode_name[0]) #using 0 index to grab the name of the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name                  0\n",
       "long_trees                   0\n",
       "lat_trees                    0\n",
       "diameter_breast_height_CM    0\n",
       "native                       0\n",
       "age_at_obs                   0\n",
       "adj_reports                  0\n",
       "norm_prcp_mm_total           0\n",
       "norm_snow_mm_total           0\n",
       "distance_between             0\n",
       "tree_id                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate no missing values\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Feature Engineering\n",
    "\n",
    "### 3.5.0 Create New Fields - Daily Averages\n",
    "\n",
    "I want to create a daily average field for the snow and rainfall, using 365 days (understandably) as the denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column for daily rainfall avg\n",
    "X_train['prcp_daily_avg'] = X_train['norm_prcp_mm_total'].div(365.0)\n",
    "X_train['snow_daily_avg'] = X_train['norm_snow_mm_total'].div(365.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Feature Scaling\n",
    "\n",
    "I'll start by reviewing distributions of our numerical variables to see if we need to do any column specifc scaling or if we can apply some standard methodology."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.x Categorical Encoding\n",
    "\n",
    "We'll need to encode our categorical features. And for our tree names, we'll likely need to group together some of the less frequent options so we don't overwhelm our model with a crazy number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['common_name', 'native'], dtype='object')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns = trees_df.select_dtypes(include='object').columns\n",
    "\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Red maple                     5218\n",
       "Apple/crabapple               4653\n",
       "Norway maple                  4510\n",
       "Purpleleaf plum variety       4313\n",
       "(smooth) japanese maple       4193\n",
       "                              ... \n",
       "Silver leaved mountain gum       2\n",
       "Doublefile viburnum              2\n",
       "Shade king red maple             2\n",
       "Spindle tree                     2\n",
       "Hokusai flowering cherry         2\n",
       "Name: common_name, Length: 670, dtype: int64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view value_counts of common_name field\n",
    "trees_df['common_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                             common_name\n",
       "(arnold) tulip tree               61             1\n",
       "Pleated viburnum                  8              1\n",
       "Purple crabapple                  2              1\n",
       "Prospector elm                    19             1\n",
       "Professor sprenger crabapple      3              1\n",
       "                                                ..\n",
       "Emerald avenue european hornbeam  11             1\n",
       "Elizabeth magnolia                6              1\n",
       "Easy street maple                 5              1\n",
       "Eastern redcedar                  15             1\n",
       "Zumi crabapple                    61             1\n",
       "Length: 436, dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many of the 670 categories have less than 100 records?\n",
    "\n",
    "vc = pd.DataFrame(trees_df['common_name'].value_counts())\n",
    "\n",
    "vc.reset_index(inplace=True)\n",
    "\n",
    "vc[vc['common_name'] < 100].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "introduced             116127\n",
       "no_info                 32616\n",
       "naturally_occurring      9261\n",
       "Name: native, dtype: int64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view value_counts of common_name field\n",
    "trees_df['native'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1.0 Convert common_name Field to Group Names with < 100 Occurences\n",
    "\n",
    "This will limit the number of columns we have. We won't do thes ame for the native field. We'll do it by defining a function that can be utilized later as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_categories(df, col, n_limit):\n",
    "    \"\"\" Store categories in df[col] with counts less than the specified n and overwrite the corresponding values in the df with 'Other' \"\"\"\n",
    "    groups = df[col]\n",
    "    group_counts = groups.value_counts()\n",
    "    mask = groups.isin(group_counts[group_counts<n_limit].index)\n",
    "    df[mask] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                          12408\n",
       "Red maple                       4684\n",
       "Apple/crabapple                 3733\n",
       "Norway maple                    3667\n",
       "Purpleleaf plum variety         3455\n",
       "                               ...  \n",
       "Autumn applause white ash        102\n",
       "Vanessa parrotia                 102\n",
       "Skyline honey locust             101\n",
       "Princess diana serviceberry      100\n",
       "Yellowwood                       100\n",
       "Name: common_name, Length: 198, dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use our group categories feature on our X_train set\n",
    "group_categories(X_train, 'common_name', 100)\n",
    "\n",
    "X_train['common_name'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1.1 Run OHE On Our Object Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(drop='first', handle_unknown='ignore')"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a onehotencoder instance\n",
    "ohe = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "#fit on our test set\n",
    "ohe.fit(X_train[['common_name','native']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
