{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Pre-Processing & Training\n",
    "\n",
    "In our last step, we did some joining of our data based on latitude and longitude and explored our features. In this next step we will prepare for modeling by tuning our features, and maybe even adding a feature or two. We will have some challenges with finding the right mix and tuning of features when our initial correlation review didn't show much to work with. Maybe more challenging will be how to deal with our fairly imbalanced data.\n",
    "\n",
    "## 3.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RepeatedStratifiedKFold, cross_val_score, KFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC #using SMOTENC because it accepts a mix of numeric and categorical values\n",
    "\n",
    "#imports for saving model\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planted_date</th>\n",
       "      <th>most_recent_observation</th>\n",
       "      <th>common_name</th>\n",
       "      <th>long_trees</th>\n",
       "      <th>lat_trees</th>\n",
       "      <th>diameter_breast_height_CM</th>\n",
       "      <th>condition</th>\n",
       "      <th>native</th>\n",
       "      <th>age_at_obs</th>\n",
       "      <th>condition_index</th>\n",
       "      <th>...</th>\n",
       "      <th>adj_reports</th>\n",
       "      <th>norm_prcp_mm_total</th>\n",
       "      <th>norm_snow_mm_total</th>\n",
       "      <th>distance_between</th>\n",
       "      <th>temp_avg_normal</th>\n",
       "      <th>temp_min_normal</th>\n",
       "      <th>temp_max_normal</th>\n",
       "      <th>temp_range_normal</th>\n",
       "      <th>prcp_mm_normal</th>\n",
       "      <th>tree_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991-07-22</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>(european) white birch</td>\n",
       "      <td>-122.282080</td>\n",
       "      <td>47.635207</td>\n",
       "      <td>40.64</td>\n",
       "      <td>excellent</td>\n",
       "      <td>introduced</td>\n",
       "      <td>27.765115</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947927</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-07-30</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>Kwanzan flowering cherry</td>\n",
       "      <td>-122.318952</td>\n",
       "      <td>47.649141</td>\n",
       "      <td>5.08</td>\n",
       "      <td>fair</td>\n",
       "      <td>no_info</td>\n",
       "      <td>27.743212</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.367105</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1991-07-25</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>Japanese snowbell tree</td>\n",
       "      <td>-122.299891</td>\n",
       "      <td>47.637863</td>\n",
       "      <td>2.54</td>\n",
       "      <td>excellent</td>\n",
       "      <td>introduced</td>\n",
       "      <td>27.756901</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.145690</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  planted_date most_recent_observation               common_name  long_trees  \\\n",
       "0   1991-07-22              2019-04-27    (european) white birch -122.282080   \n",
       "1   1991-07-30              2019-04-27  Kwanzan flowering cherry -122.318952   \n",
       "2   1991-07-25              2019-04-27    Japanese snowbell tree -122.299891   \n",
       "\n",
       "   lat_trees  diameter_breast_height_CM  condition      native  age_at_obs  \\\n",
       "0  47.635207                      40.64  excellent  introduced   27.765115   \n",
       "1  47.649141                       5.08       fair     no_info   27.743212   \n",
       "2  47.637863                       2.54  excellent  introduced   27.756901   \n",
       "\n",
       "   condition_index  ... adj_reports norm_prcp_mm_total norm_snow_mm_total  \\\n",
       "0              5.0  ...         237        1071.925479                0.0   \n",
       "1              3.0  ...         237        1071.925479                0.0   \n",
       "2              5.0  ...         237        1071.925479                0.0   \n",
       "\n",
       "   distance_between  temp_avg_normal  temp_min_normal  temp_max_normal  \\\n",
       "0          0.947927             53.2             45.7             60.8   \n",
       "1          3.367105             53.2             45.7             60.8   \n",
       "2          1.145690             53.2             45.7             60.8   \n",
       "\n",
       "   temp_range_normal  prcp_mm_normal  tree_id  \n",
       "0               15.0         960.628        1  \n",
       "1               15.0         960.628        2  \n",
       "2               15.0         960.628        3  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_df = pd.read_csv('../data/data_outputs/seattle_trees_explored.csv')\n",
    "\n",
    "trees_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prep DF for Train-Test split\n",
    "\n",
    "We'll take another look at the columns, as we can likely drop the additional reference info from our climate 'prcp' data source. And then we'll split our dependent and independent variables.\n",
    "\n",
    "### 3.2.0 Drop Unecessary Columns\n",
    "\n",
    "We'll drop the reference cols from climate data like I mentioned above, but also the 'condition' column because it is duplicative of our target feature. Our tree_id because it has no more use. And our date cols, because we have the calculated age feature that will be our variable related to dates/ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158004 entries, 0 to 158003\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   planted_date               155133 non-null  object \n",
      " 1   most_recent_observation    157999 non-null  object \n",
      " 2   common_name                157332 non-null  object \n",
      " 3   long_trees                 158004 non-null  float64\n",
      " 4   lat_trees                  158004 non-null  float64\n",
      " 5   diameter_breast_height_CM  158004 non-null  float64\n",
      " 6   condition                  158004 non-null  object \n",
      " 7   native                     158004 non-null  object \n",
      " 8   age_at_obs                 155128 non-null  float64\n",
      " 9   condition_index            158004 non-null  float64\n",
      " 10  nearest_station            158004 non-null  object \n",
      " 11  station_id                 158004 non-null  object \n",
      " 12  station_name               158004 non-null  object \n",
      " 13  lat_prcp                   158004 non-null  float64\n",
      " 14  long_prcp                  158004 non-null  float64\n",
      " 15  adj_reports                158004 non-null  int64  \n",
      " 16  norm_prcp_mm_total         158004 non-null  float64\n",
      " 17  norm_snow_mm_total         158004 non-null  float64\n",
      " 18  distance_between           158004 non-null  float64\n",
      " 19  temp_avg_normal            158004 non-null  float64\n",
      " 20  temp_min_normal            158004 non-null  float64\n",
      " 21  temp_max_normal            158004 non-null  float64\n",
      " 22  temp_range_normal          158004 non-null  float64\n",
      " 23  prcp_mm_normal             158004 non-null  float64\n",
      " 24  tree_id                    158004 non-null  int64  \n",
      "dtypes: float64(15), int64(2), object(8)\n",
      "memory usage: 30.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#View our columns\n",
    "trees_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop our columns that are reference from climate dataset and the original condition column (which we used to create our target index feature)\n",
    "trees_df = trees_df.drop(columns=['nearest_station', 'station_id',\n",
    "       'station_name', 'lat_prcp', 'long_prcp', 'condition', 'planted_date','most_recent_observation','tree_id','long_trees','lat_trees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['common_name', 'diameter_breast_height_CM', 'native', 'age_at_obs',\n",
       "       'condition_index', 'adj_reports', 'norm_prcp_mm_total',\n",
       "       'norm_snow_mm_total', 'distance_between', 'temp_avg_normal',\n",
       "       'temp_min_normal', 'temp_max_normal', 'temp_range_normal',\n",
       "       'prcp_mm_normal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Sample Dataset to Make Size More Manageable\n",
    "One model may not be too crazy, but running a gridsearch CV on hundreds of thousands of rows may be a bit much for me. I'll start with a sample of 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_sample = trees_df.sample(n=10000, replace=False, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Split Dependent and Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X = trees_sample.drop(columns=['condition_index'])\n",
    "y = trees_sample['condition_index']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train-Test Split\n",
    "We'll use an 80:20 split here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 13) (8000,) (2000, 13) (2000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Impute Missing Values\n",
    "\n",
    "We will use the median for our age at observation and mode for common name.\n",
    "\n",
    "### 3.4.0 Calculate Modes and Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_median_age = X_train['age_at_obs'].median()\n",
    "X_mode_name = X_train['common_name'].mode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Impute Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute planted_date\n",
    "X_train['age_at_obs'] = X_train['age_at_obs'].fillna(X_median_age)\n",
    "X_train['common_name'] = X_train['common_name'].fillna(X_mode_name[0]) #using 0 index to grab the name of the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name                  0\n",
       "diameter_breast_height_CM    0\n",
       "native                       0\n",
       "age_at_obs                   0\n",
       "adj_reports                  0\n",
       "norm_prcp_mm_total           0\n",
       "norm_snow_mm_total           0\n",
       "distance_between             0\n",
       "temp_avg_normal              0\n",
       "temp_min_normal              0\n",
       "temp_max_normal              0\n",
       "temp_range_normal            0\n",
       "prcp_mm_normal               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate no missing values\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Simple Feature Engineering\n",
    "\n",
    "Before running a first test model, I'll do some basic feature engineering. After testing on a single model we'll move into doing further tuning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Categorical Encoding\n",
    "\n",
    "We'll need to encode our categorical features. And for our tree names, we'll likely need to group together some of the less frequent options so we don't overwhelm our model with a crazy number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['common_name', 'native'], dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns = trees_df.select_dtypes(include='object').columns\n",
    "\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Red maple                     5218\n",
       "Apple/crabapple               4653\n",
       "Norway maple                  4510\n",
       "Purpleleaf plum variety       4313\n",
       "(smooth) japanese maple       4193\n",
       "                              ... \n",
       "Silver leaved mountain gum       2\n",
       "Doublefile viburnum              2\n",
       "Shade king red maple             2\n",
       "Spindle tree                     2\n",
       "Hokusai flowering cherry         2\n",
       "Name: common_name, Length: 670, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view value_counts of common_name field\n",
    "trees_df['common_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                         common_name\n",
       "(pink) idaho locust           9              1\n",
       "Serbian spruce                3              1\n",
       "Pagoda dogwood                7              1\n",
       "Parney cotoneaster            3              1\n",
       "Pink spires crabapple         5              1\n",
       "                                            ..\n",
       "Eugene`s (carolina) poplar    6              1\n",
       "European white elm            8              1\n",
       "Fastigiata western red cedar  5              1\n",
       "Firefall freeman maple        6              1\n",
       "Wych elm                      3              1\n",
       "Length: 163, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many of the 670 categories have less than 10 records?\n",
    "\n",
    "vc = pd.DataFrame(trees_df['common_name'].value_counts())\n",
    "\n",
    "vc.reset_index(inplace=True)\n",
    "\n",
    "vc[vc['common_name'] < 10].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "introduced             116127\n",
       "no_info                 32616\n",
       "naturally_occurring      9261\n",
       "Name: native, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view value_counts of common_name field\n",
    "trees_df['native'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1.0 Convert common_name Field to Group Names with < 100 Occurences\n",
    "\n",
    "This will limit the number of columns we have. We won't do thes ame for the native field. We'll do it by defining a function that can be utilized later as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_categories(df, col, n_limit):\n",
    "    \"\"\" Store categories in df[col] with counts less than the specified n and overwrite the corresponding values in the df with 'Other' \"\"\"\n",
    "    groups = df[col]\n",
    "    group_counts = groups.value_counts()\n",
    "    mask = groups.isin(group_counts[group_counts<n_limit].index)\n",
    "    df.loc[mask, col] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                       1032\n",
       "Red maple                    330\n",
       "Purpleleaf plum variety      237\n",
       "Norway maple                 216\n",
       "Apple/crabapple              215\n",
       "                            ... \n",
       "Pacific dogwood               10\n",
       "Largeleaf crabapple           10\n",
       "Tuscorara crapemyrtle         10\n",
       "Red cascade mountain ash      10\n",
       "Raywood narrowleaf ash        10\n",
       "Name: common_name, Length: 155, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use our group categories feature on our X_train set\n",
    "group_categories(X_train, 'common_name', 10)\n",
    "\n",
    "X_train['common_name'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1.1 Run OHE On Our Object Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(drop='first', handle_unknown='ignore')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a onehotencoder instance\n",
    "ohe = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "#fit on our test set\n",
    "ohe.fit(X_train[['common_name','native']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 First Model\n",
    "\n",
    "Now that we've done some basic tuning, let's do some transforming with the feature engineering tools we fit and run a logistic regression model to see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_name</th>\n",
       "      <th>diameter_breast_height_CM</th>\n",
       "      <th>native</th>\n",
       "      <th>age_at_obs</th>\n",
       "      <th>adj_reports</th>\n",
       "      <th>norm_prcp_mm_total</th>\n",
       "      <th>norm_snow_mm_total</th>\n",
       "      <th>distance_between</th>\n",
       "      <th>temp_avg_normal</th>\n",
       "      <th>temp_min_normal</th>\n",
       "      <th>temp_max_normal</th>\n",
       "      <th>temp_range_normal</th>\n",
       "      <th>prcp_mm_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85168</th>\n",
       "      <td>Common serviceberry</td>\n",
       "      <td>7.62</td>\n",
       "      <td>introduced</td>\n",
       "      <td>3.652368</td>\n",
       "      <td>217</td>\n",
       "      <td>849.190323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.243978</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85613</th>\n",
       "      <td>Red maple</td>\n",
       "      <td>7.62</td>\n",
       "      <td>no_info</td>\n",
       "      <td>11.641581</td>\n",
       "      <td>217</td>\n",
       "      <td>849.190323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317906</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11471</th>\n",
       "      <td>Other</td>\n",
       "      <td>12.70</td>\n",
       "      <td>introduced</td>\n",
       "      <td>19.154397</td>\n",
       "      <td>347</td>\n",
       "      <td>1138.700000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.330051</td>\n",
       "      <td>53.8</td>\n",
       "      <td>46.0</td>\n",
       "      <td>61.7</td>\n",
       "      <td>15.7</td>\n",
       "      <td>926.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57576</th>\n",
       "      <td>American hornbeam</td>\n",
       "      <td>5.08</td>\n",
       "      <td>introduced</td>\n",
       "      <td>2.965153</td>\n",
       "      <td>224</td>\n",
       "      <td>1045.880645</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.434896</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130978</th>\n",
       "      <td>Pacific sunset maple</td>\n",
       "      <td>27.94</td>\n",
       "      <td>introduced</td>\n",
       "      <td>18.929889</td>\n",
       "      <td>19</td>\n",
       "      <td>1183.835484</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.953287</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 common_name  diameter_breast_height_CM      native  \\\n",
       "85168    Common serviceberry                       7.62  introduced   \n",
       "85613              Red maple                       7.62     no_info   \n",
       "11471                  Other                      12.70  introduced   \n",
       "57576      American hornbeam                       5.08  introduced   \n",
       "130978  Pacific sunset maple                      27.94  introduced   \n",
       "\n",
       "        age_at_obs  adj_reports  norm_prcp_mm_total  norm_snow_mm_total  \\\n",
       "85168     3.652368          217          849.190323                 0.0   \n",
       "85613    11.641581          217          849.190323                 0.0   \n",
       "11471    19.154397          347         1138.700000                35.0   \n",
       "57576     2.965153          224         1045.880645                13.0   \n",
       "130978   18.929889           19         1183.835484                 5.0   \n",
       "\n",
       "        distance_between  temp_avg_normal  temp_min_normal  temp_max_normal  \\\n",
       "85168           1.243978             53.2             45.7             60.8   \n",
       "85613           0.317906             53.2             45.7             60.8   \n",
       "11471           1.330051             53.8             46.0             61.7   \n",
       "57576           3.434896             53.2             45.7             60.8   \n",
       "130978          1.953287             53.2             45.7             60.8   \n",
       "\n",
       "        temp_range_normal  prcp_mm_normal  \n",
       "85168                15.0         960.628  \n",
       "85613                15.0         960.628  \n",
       "11471                15.7         926.846  \n",
       "57576                15.0         960.628  \n",
       "130978               15.0         960.628  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Scalers and Transforms\n",
    "\n",
    "ss_scaler = StandardScaler()\n",
    "pow_trans = PowerTransformer()\n",
    "ohe = OneHotEncoder(drop='first', handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_scaler, pow_trans, ohe\n",
    "#transform with our ss_scaler\n",
    "X_train_scaled = ss_scaler.fit_transform(X_train[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','temp_min_normal','temp_max_normal','temp_range_normal','prcp_mm_normal']])\n",
    "\n",
    "#transform with our pow_trans\n",
    "X_train_scaled = pow_trans.fit_transform(X_train[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']])\n",
    "\n",
    "#transform with our ohe\n",
    "X_train_scaled = ohe.fit_transform(X_train[['common_name','native']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8000x156 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10119 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.57\n"
     ]
    }
   ],
   "source": [
    "#Initiate and run logistic regression model\n",
    "\n",
    "logreg = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1)\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'Accuracy on training data: {accuracy_score(logreg.predict(X_train_scaled), y_train):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       120\n",
      "         2.0       0.00      0.00      0.00       421\n",
      "         3.0       0.49      0.14      0.22      1921\n",
      "         4.0       0.57      0.97      0.72      4410\n",
      "         5.0       0.78      0.01      0.02      1128\n",
      "\n",
      "    accuracy                           0.57      8000\n",
      "   macro avg       0.37      0.22      0.19      8000\n",
      "weighted avg       0.54      0.57      0.45      8000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, logreg.predict(X_train_scaled)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a great accuracy to begin with, but our model isn't predicting any ones or twos, which isn't suprising based on our imbalanced data. Let's work on addressing the imbalanced data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Work on Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 4410, 4410, 4410, 4410, 4410])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use SMOTE to resample and balance our dataset\n",
    "sm = SMOTENC(random_state=42, categorical_features=[0,2])\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "np.bincount(y_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.0 Re-Run Model Using 'SMOTED' Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_scaler, pow_trans, ohe\n",
    "#transform with our ss_scaler\n",
    "X_res[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','temp_min_normal','temp_max_normal','temp_range_normal','prcp_mm_normal']] = ss_scaler.fit_transform(X_res[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','temp_min_normal','temp_max_normal','temp_range_normal','prcp_mm_normal']])\n",
    "\n",
    "#transform with our pow_trans\n",
    "X_res[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']] = pow_trans.fit_transform(X_res[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']])\n",
    "\n",
    "#transform with our ohe\n",
    "X_res_scaled = ohe.fit_transform(X_res[['common_name','native']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22050x308 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 44060 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, max_iter=500, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, max_iter=500, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, max_iter=500, solver='liblinear')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initiate and run logistic regression model\n",
    "\n",
    "logreg = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1)\n",
    "\n",
    "logreg.fit(X_res_scaled, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.42\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.50      0.68      0.58      4410\n",
      "         2.0       0.35      0.50      0.41      4410\n",
      "         3.0       0.35      0.25      0.29      4410\n",
      "         4.0       0.44      0.28      0.34      4410\n",
      "         5.0       0.45      0.39      0.42      4410\n",
      "\n",
      "    accuracy                           0.42     22050\n",
      "   macro avg       0.42      0.42      0.41     22050\n",
      "weighted avg       0.42      0.42      0.41     22050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on training data: {accuracy_score(logreg.predict(X_res_scaled), y_res):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_res, logreg.predict(X_res_scaled)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "The overall accuracy of the model is worse, but we took a step in the right direction as it is now predicting in the whole range off possible values. With basically no hyperparamter tuning, we still have work to do.\n",
    "\n",
    "## 3.8 Tuning\n",
    "\n",
    "I tested out the pretty simple tuning but I'd actually like to do some different scaling depending on the feature in preperation for hyperparamter tuning. I'll do that now on my resampled dataframe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.0 Impute and Scale Features\n",
    "\n",
    "I'm going to use a simpleimputer this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initatite Imputeres and Scalers\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing') #going to impute missing this time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.1 Try Another Approach On Imbalanced Data\n",
    "\n",
    "Rather than using my resamples SMOTE dataframe, I want to try applying all of the other transformations the same, but this time on my initial 10,000 record sample using RepeatedStratifiedKFold cross validation.\n",
    "\n",
    "#### 3.8.1.0 Apply Transformation to Initial Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this time I'm going to just call fit_transform on my earlier imputers and scalers\n",
    "\n",
    "X_train['age_at_obs'] = num_imputer.fit_transform(X_train[['age_at_obs']])\n",
    "X_train['common_name'] = cat_imputer.fit_transform(X_train[['common_name']])\n",
    "X_train[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']] = pow_trans.fit_transform(X_train[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']])\n",
    "X_train[['age_at_obs','norm_prcp_mm_total']] = ss_scaler.fit_transform(X_train[['age_at_obs','norm_prcp_mm_total']])\n",
    "X_train_transformed = ohe.fit_transform(X_train[['common_name','native']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8000x156 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10119 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1.1 Define Our Cross-Validation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1.2 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model with our best params so far\n",
    "logreg2 = LogisticRegression(random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1.3 Fit and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.57\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       120\n",
      "         2.0       0.00      0.00      0.00       421\n",
      "         3.0       0.48      0.15      0.22      1921\n",
      "         4.0       0.58      0.96      0.72      4410\n",
      "         5.0       0.69      0.02      0.03      1128\n",
      "\n",
      "    accuracy                           0.57      8000\n",
      "   macro avg       0.35      0.23      0.20      8000\n",
      "weighted avg       0.53      0.57      0.46      8000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "logreg2.fit(X_train_transformed, y_train)\n",
    "print(f'Accuracy on training data: {accuracy_score(logreg2.predict(X_train_transformed), y_train):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, logreg2.predict(X_train_transformed)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "Using the StratifiedKFold didn't allow us to pick up any of the imbalanced classes in our prediction, so we'll use the SMOTE resample going forward."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Try Different Models\n",
    "\n",
    "The best we got with logistic regression was 47% accuracy. That leaves much to be desired, so let's try something other than this type of model. We'll use our X_res_scaled and y_res for consistency.\n",
    "\n",
    "### 3.9.0 Test Set Performance Comparison\n",
    "\n",
    "If we do some simple default setting comparison between KNeighbors, Decision Trees, and Random Forest, it could give us a good sense of where to focus our time going forward."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.0.0 Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list types of models to run\n",
    "models = {'logreg': LogisticRegression(),\n",
    "          'knn': KNeighborsClassifier(),\n",
    "          'dec_tree': DecisionTreeClassifier(),\n",
    "          'rand_for': RandomForestClassifier(),\n",
    "          'ada': AdaBoostClassifier(),\n",
    "          'gradient': GradientBoostingClassifier()\n",
    "          }\n",
    "\n",
    "#create blank list to store results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Loop through models, score and save\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True) #using KFold this time rather than setting up a whole GridSearch\n",
    "    cv_results = cross_val_score(model, X_res_scaled, y_res, cv=kf)\n",
    "    results.append(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.4277551 , 0.43591837, 0.42394558, 0.41061224, 0.42068027,\n",
       "        0.42693878]),\n",
       " array([0.28952381, 0.27673469, 0.28544218, 0.28571429, 0.28380952,\n",
       "        0.27836735]),\n",
       " array([0.43455782, 0.44544218, 0.43673469, 0.41877551, 0.43482993,\n",
       "        0.43836735]),\n",
       " array([0.43782313, 0.44734694, 0.43782313, 0.42176871, 0.43428571,\n",
       "        0.43891156]),\n",
       " array([0.36      , 0.36462585, 0.36952381, 0.36027211, 0.36353741,\n",
       "        0.35945578]),\n",
       " array([0.41360544, 0.42721088, 0.41306122, 0.40380952, 0.41414966,\n",
       "        0.42068027]),\n",
       " array([0.41088435, 0.42204082, 0.40707483, 0.39727891, 0.40789116,\n",
       "        0.4152381 ]),\n",
       " array([0.25741497, 0.2462585 , 0.24598639, 0.25142857, 0.24761905,\n",
       "        0.23782313]),\n",
       " array([0.40870748, 0.42176871, 0.40680272, 0.39564626, 0.40843537,\n",
       "        0.41387755]),\n",
       " array([0.41006803, 0.4214966 , 0.40598639, 0.39564626, 0.40843537,\n",
       "        0.41469388]),\n",
       " array([0.37006803, 0.3692517 , 0.36326531, 0.36544218, 0.3662585 ,\n",
       "        0.36435374]),\n",
       " array([0.39782313, 0.40680272, 0.39863946, 0.39292517, 0.40489796,\n",
       "        0.39863946])]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.0.1 Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "Our Random Forest looks to be just slightly better than a decision tree model as is already better than our logistic regression model without any tuning. Let's explore this model futher.\n",
    "\n",
    "### 3.9.1 Random Forest Classifier\n",
    "\n",
    "This time I'll use RandomizedSearchCV to tune params. Source: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "#### 3.9.1.0 Create Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['log2', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "#list out our different params\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] #number of trees in the forest\n",
    "max_features = ['log2','sqrt'] #number of features to consider at each split\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)] #max levels in tree\n",
    "min_samples_split = [2,5,10] #min samples required to split a node\n",
    "min_samples_leaf = [1,2,4] #min samples at each leaf node\n",
    "bootstrap = [True, False] #sampling method using bootsrap or not\n",
    "\n",
    "#Create random grid\n",
    "rand_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(rand_grid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1.1 One Hot Encode\n",
    "\n",
    "I want to try this without any scaling, but I will do my onehotencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name                  category\n",
       "diameter_breast_height_CM     float64\n",
       "native                       category\n",
       "age_at_obs                    float64\n",
       "adj_reports                   float64\n",
       "norm_prcp_mm_total            float64\n",
       "norm_snow_mm_total            float64\n",
       "distance_between              float64\n",
       "temp_avg_normal               float64\n",
       "temp_min_normal               float64\n",
       "temp_max_normal               float64\n",
       "temp_range_normal             float64\n",
       "prcp_mm_normal                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update to categorical dtypes\n",
    "X_res['common_name'] = X_res.common_name.astype('category')\n",
    "X_res['native'] = X_res.native.astype('category')\n",
    "\n",
    "X_res.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish ohe\n",
    "ohe = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "#fit and transform\n",
    "x_res_encoded = ohe.fit_transform(X_res[['common_name','native']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1.1 Fit with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=   5.3s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=   5.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.3s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   6.9s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   6.8s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   6.9s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   6.9s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400; total time=   8.9s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400; total time=   9.4s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400; total time=   9.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400; total time=   9.2s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400; total time=  10.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1200; total time=   4.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1200; total time=   4.3s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1200; total time=   4.3s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1200; total time=   4.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1200; total time=   4.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   8.3s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   8.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   8.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   8.5s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   8.4s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.2s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.1s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.1s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.1s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.1s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=   7.3s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=   7.5s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   3.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.2s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.2s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1800; total time=  12.0s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1800; total time=  12.3s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1800; total time=  12.1s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1800; total time=  12.2s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1800; total time=  12.1s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  12.1s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  12.2s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  12.4s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  12.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  12.6s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=  12.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=  12.8s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=  12.9s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=  13.2s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=2000; total time=  13.1s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=   3.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=   3.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time=   3.6s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   4.6s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   4.7s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   4.8s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   4.8s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000; total time=   4.8s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.2s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.2s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.3s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.6s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.3s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1400; total time=   5.6s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1400; total time=   5.7s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1400; total time=   5.7s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1400; total time=   5.7s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1400; total time=   5.7s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  12.4s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  12.5s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  12.5s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   2.2s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   2.3s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   2.3s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   2.3s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   2.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.8s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.4s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.4s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.5s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   5.9s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.0s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.0s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.7s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   7.7s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1200; total time=   7.3s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1200; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1200; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1200; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1200; total time=   7.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.3s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.1s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.0s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.0s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=  10.2s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   2.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   2.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  11.4s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  11.4s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  11.5s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  11.5s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000; total time=  11.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   2.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   2.9s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time=   4.0s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600; total time=   4.1s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.4s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.2s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=   1.8s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=   1.8s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=   1.9s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=   1.9s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=   1.9s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=110, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time=   3.5s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=60, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=600; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800; total time=  10.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800; total time=  10.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800; total time=  10.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800; total time=  10.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800; total time=  10.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=   7.9s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   5.3s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  10.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  11.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  11.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  11.2s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=2000; total time=  11.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=  11.2s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=  11.2s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=  11.5s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=  11.6s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1800; total time=  11.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110],\n",
       "                                        'max_features': ['log2', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "#Random Search Cross-Val\n",
    "rf_rand = RandomizedSearchCV(estimator=rf, param_distributions=rand_grid, n_iter=50, cv=5, verbose=2, random_state=42) #sample 50 param settings, 5 fold cross-val, computation time display\n",
    "\n",
    "#fit the model on the non-scaled data\n",
    "rf_rand.fit(x_res_encoded, y_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1.2 Review Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 110,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rand.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1.3 Fit Model Using Best Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.42\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.50      0.68      0.58      4410\n",
      "         2.0       0.35      0.50      0.41      4410\n",
      "         3.0       0.35      0.25      0.29      4410\n",
      "         4.0       0.44      0.27      0.34      4410\n",
      "         5.0       0.45      0.40      0.42      4410\n",
      "\n",
      "    accuracy                           0.42     22050\n",
      "   macro avg       0.42      0.42      0.41     22050\n",
      "weighted avg       0.42      0.42      0.41     22050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run a fit with those params and view more details scoring\n",
    "\n",
    "#setup model\n",
    "rf_tuned = RandomForestClassifier(n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features='sqrt', max_depth=110, bootstrap=True)\n",
    "\n",
    "#fit model\n",
    "rf_tuned.fit(x_res_encoded, y_res)\n",
    "\n",
    "#review scores\n",
    "print(f'Accuracy on training data: {accuracy_score(rf_tuned.predict(x_res_encoded), y_res):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_res, rf_tuned.predict(x_res_encoded)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "This actually didn't get us much more than our inital model. Either way, it is the best we've gotten so far so let's try it out on the test set.\n",
    "\n",
    "#### 3.9.1.4 Scale and Test for Better Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-transform to be able to appropriately fit my ohe\n",
    "X_res['age_at_obs'] = num_imputer.fit_transform(X_res[['age_at_obs']])\n",
    "X_res['common_name'] = cat_imputer.fit_transform(X_res[['common_name']])\n",
    "X_res[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']] = pow_trans.fit_transform(X_res[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']])\n",
    "X_res[['age_at_obs','norm_prcp_mm_total']] = ss_scaler.fit_transform(X_res[['age_at_obs','norm_prcp_mm_total']])\n",
    "\n",
    "#re-fit ohe\n",
    "X_res_scaled = ohe.fit_transform(X_res[['common_name','native']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.42\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.50      0.68      0.58      4410\n",
      "         2.0       0.35      0.50      0.41      4410\n",
      "         3.0       0.34      0.27      0.30      4410\n",
      "         4.0       0.45      0.26      0.33      4410\n",
      "         5.0       0.45      0.40      0.42      4410\n",
      "\n",
      "    accuracy                           0.42     22050\n",
      "   macro avg       0.42      0.42      0.41     22050\n",
      "weighted avg       0.42      0.42      0.41     22050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check Results\n",
    "\n",
    "#fit model\n",
    "rf_tuned.fit(X_res_scaled, y_res)\n",
    "\n",
    "#review scores\n",
    "print(f'Accuracy on training data: {accuracy_score(rf_tuned.predict(X_res_scaled), y_res):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_res, rf_tuned.predict(X_res_scaled)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't add anything, which makes sense because RF is pretty resilient to different scaling. Let's move forward sticking with only the imputing and categorical encoding.\n",
    "\n",
    "### 3.9.2 Evaluate RF Model on Test Set\n",
    "\n",
    "The first thing we'll need to do is process our X_test using the same steps we did on our X_train.\n",
    "\n",
    "#### 3.9.2.0 Pre-Processing X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name                  category\n",
       "diameter_breast_height_CM     float64\n",
       "native                       category\n",
       "age_at_obs                    float64\n",
       "adj_reports                     int64\n",
       "norm_prcp_mm_total            float64\n",
       "norm_snow_mm_total            float64\n",
       "distance_between              float64\n",
       "temp_avg_normal               float64\n",
       "temp_min_normal               float64\n",
       "temp_max_normal               float64\n",
       "temp_range_normal             float64\n",
       "prcp_mm_normal                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Update object to categorical\n",
    "X_test['common_name'] = X_test.common_name.astype('category')\n",
    "X_test['native'] = X_test.native.astype('category')\n",
    "\n",
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0, 1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#refit imputers\n",
    "num_imputer.fit(X_res[['age_at_obs']])\n",
    "cat_imputer.fit(X_res[['common_name']])\n",
    "\n",
    "#refit ohe on x_res\n",
    "ohe.fit(X_res[['common_name','native']])\n",
    "\n",
    "#Apply transformations from the steps we fitted earlier in the model\n",
    "X_test['age_at_obs'] = num_imputer.transform(X_test[['age_at_obs']])\n",
    "X_test['common_name'] = cat_imputer.transform(X_test[['common_name']])\n",
    "\n",
    "X_test_transformed = ohe.transform(X_test[['common_name','native']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x308 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1707 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.54\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.15      0.05      0.08        39\n",
      "         2.0       0.00      0.00      0.00        93\n",
      "         3.0       0.00      0.00      0.00       503\n",
      "         4.0       0.55      0.98      0.70      1091\n",
      "         5.0       0.35      0.03      0.06       274\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.21      0.21      0.17      2000\n",
      "weighted avg       0.35      0.54      0.39      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_tuned.predict(X_test_transformed)\n",
    "\n",
    "print(f'Accuracy on training data: {accuracy_score(y_pred, y_test):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "\\\n",
    "As we'd expect from a lower training result, our test results aren't all that much better than a random guess if my math is correct. I will go ahead and export the model, but will continue to research and round back to see if there are any useful features that could be added or engineered to achieve better results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Save Model\n",
    "\n",
    "### 4.0.0 Define Saving Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions for saving model provided by Springboard Guided Capstone\n",
    "def _save_file(data, fpath):\n",
    "    valid_ftypes = ['.csv', '.pkl']\n",
    "    \n",
    "    assert (fpath[-4:] in valid_ftypes), \"Invalid file type.  Use '.csv' or '.pkl'\"\n",
    "\n",
    "    # Figure out what kind of file we're dealing with by name\n",
    "    if fpath[-3:] == 'csv':\n",
    "        data.to_csv(fpath, index=False)\n",
    "    elif fpath[-3:] == 'pkl':\n",
    "        with open(fpath, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "def save_file(data, fname, dname):\n",
    "    \"\"\"Save a datafile (data) to a specific location (dname) and filename (fname)\n",
    "    \n",
    "    Currently valid formats are limited to CSV or PKL.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(dname):\n",
    "        os.mkdir(dname)\n",
    "        print(f'Directory {dname} was created.')\n",
    "        \n",
    "    fpath = os.path.join(dname, fname)\n",
    "    \n",
    "    \n",
    "    if os.path.exists(fpath):\n",
    "        print(\"A file already exists with this name.\\n\")\n",
    "\n",
    "        yesno = None\n",
    "        while yesno != \"Y\" and yesno != \"N\":\n",
    "            yesno = input('Do you want to overwrite? (Y/N)').strip()[0].capitalize()\n",
    "            if yesno == \"Y\":\n",
    "                print(f'Writing file.  \"{fpath}\"')\n",
    "                _save_file(data, fpath)\n",
    "                break  # Not required\n",
    "            elif yesno == \"N\":\n",
    "                print('\\nPlease re-run this cell with a new filename.')\n",
    "                break  # Not required\n",
    "            else:\n",
    "                print('\\nUnknown input, please enter \"Y\" or \"N\".')\n",
    "\n",
    "    else:  # path does not exist, ok to save the file\n",
    "        print(f'Writing file.  \"{fpath}\"')\n",
    "        _save_file(data, fpath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.1 Identify Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf_rand.best_estimator_\n",
    "rf_model.version = '1.0'\n",
    "rf_model.pandas_version = pd.__version__\n",
    "rf_model.numpy_version = np.__version__\n",
    "rf_model.sklearn_version = sklearn_version\n",
    "rf_model.X_columns = [col for col in X_train.columns]\n",
    "rf_model.build_datetime = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file.  \"../models/trees_rf_model.pkl\"\n"
     ]
    }
   ],
   "source": [
    "#Save the model to the new /models folder\n",
    "modelpath = '../models/'\n",
    "save_file(rf_model, 'trees_rf_model.pkl', modelpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
