{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Pre-Processing & Training\n",
    "\n",
    "In our last step, we did some joining of our data based on latitude and longitude and explored our features. In this next step we will prepare for modeling by tuning our features, and maybe even adding a feature or two. We will have some challenges with finding the right mix and tuning of features when our initial correlation review didn't show much to work with. Maybe more challenging will be how to deal with our fairly imbalanced data.\n",
    "\n",
    "## 3.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RepeatedStratifiedKFold, cross_val_score, KFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC #using SMOTENC because it accepts a mix of numeric and categorical values\n",
    "\n",
    "#imports for saving model\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planted_date</th>\n",
       "      <th>most_recent_observation</th>\n",
       "      <th>common_name</th>\n",
       "      <th>long_trees</th>\n",
       "      <th>lat_trees</th>\n",
       "      <th>diameter_breast_height_CM</th>\n",
       "      <th>condition</th>\n",
       "      <th>native</th>\n",
       "      <th>age_at_obs</th>\n",
       "      <th>condition_index</th>\n",
       "      <th>...</th>\n",
       "      <th>adj_reports</th>\n",
       "      <th>norm_prcp_mm_total</th>\n",
       "      <th>norm_snow_mm_total</th>\n",
       "      <th>distance_between</th>\n",
       "      <th>temp_avg_normal</th>\n",
       "      <th>temp_min_normal</th>\n",
       "      <th>temp_max_normal</th>\n",
       "      <th>temp_range_normal</th>\n",
       "      <th>prcp_mm_normal</th>\n",
       "      <th>tree_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991-07-22</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>(european) white birch</td>\n",
       "      <td>-122.282080</td>\n",
       "      <td>47.635207</td>\n",
       "      <td>40.64</td>\n",
       "      <td>excellent</td>\n",
       "      <td>introduced</td>\n",
       "      <td>27.765115</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947927</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-07-30</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>Kwanzan flowering cherry</td>\n",
       "      <td>-122.318952</td>\n",
       "      <td>47.649141</td>\n",
       "      <td>5.08</td>\n",
       "      <td>fair</td>\n",
       "      <td>no_info</td>\n",
       "      <td>27.743212</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.367105</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1991-07-25</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>Japanese snowbell tree</td>\n",
       "      <td>-122.299891</td>\n",
       "      <td>47.637863</td>\n",
       "      <td>2.54</td>\n",
       "      <td>excellent</td>\n",
       "      <td>introduced</td>\n",
       "      <td>27.756901</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>1071.925479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.145690</td>\n",
       "      <td>53.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>60.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960.628</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  planted_date most_recent_observation               common_name  long_trees  \\\n",
       "0   1991-07-22              2019-04-27    (european) white birch -122.282080   \n",
       "1   1991-07-30              2019-04-27  Kwanzan flowering cherry -122.318952   \n",
       "2   1991-07-25              2019-04-27    Japanese snowbell tree -122.299891   \n",
       "\n",
       "   lat_trees  diameter_breast_height_CM  condition      native  age_at_obs  \\\n",
       "0  47.635207                      40.64  excellent  introduced   27.765115   \n",
       "1  47.649141                       5.08       fair     no_info   27.743212   \n",
       "2  47.637863                       2.54  excellent  introduced   27.756901   \n",
       "\n",
       "   condition_index  ... adj_reports norm_prcp_mm_total norm_snow_mm_total  \\\n",
       "0              5.0  ...         237        1071.925479                0.0   \n",
       "1              3.0  ...         237        1071.925479                0.0   \n",
       "2              5.0  ...         237        1071.925479                0.0   \n",
       "\n",
       "   distance_between  temp_avg_normal  temp_min_normal  temp_max_normal  \\\n",
       "0          0.947927             53.2             45.7             60.8   \n",
       "1          3.367105             53.2             45.7             60.8   \n",
       "2          1.145690             53.2             45.7             60.8   \n",
       "\n",
       "   temp_range_normal  prcp_mm_normal  tree_id  \n",
       "0               15.0         960.628        1  \n",
       "1               15.0         960.628        2  \n",
       "2               15.0         960.628        3  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_df = pd.read_csv('../data/data_outputs/seattle_trees_explored.csv')\n",
    "\n",
    "trees_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prep DF for Train-Test split\n",
    "\n",
    "We'll take another look at the columns, as we can likely drop the additional reference info from our climate 'prcp' data source. And then we'll split our dependent and independent variables.\n",
    "\n",
    "### 3.2.0 Drop Unecessary Columns\n",
    "\n",
    "We'll drop the reference cols from climate data like I mentioned above, but also the 'condition' column because it is duplicative of our target feature. Our tree_id because it has no more use. And our date cols, because we have the calculated age feature that will be our variable related to dates/ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158004 entries, 0 to 158003\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   planted_date               155133 non-null  object \n",
      " 1   most_recent_observation    157999 non-null  object \n",
      " 2   common_name                157332 non-null  object \n",
      " 3   long_trees                 158004 non-null  float64\n",
      " 4   lat_trees                  158004 non-null  float64\n",
      " 5   diameter_breast_height_CM  158004 non-null  float64\n",
      " 6   condition                  158004 non-null  object \n",
      " 7   native                     158004 non-null  object \n",
      " 8   age_at_obs                 155128 non-null  float64\n",
      " 9   condition_index            158004 non-null  float64\n",
      " 10  nearest_station            158004 non-null  object \n",
      " 11  station_id                 158004 non-null  object \n",
      " 12  station_name               158004 non-null  object \n",
      " 13  lat_prcp                   158004 non-null  float64\n",
      " 14  long_prcp                  158004 non-null  float64\n",
      " 15  adj_reports                158004 non-null  int64  \n",
      " 16  norm_prcp_mm_total         158004 non-null  float64\n",
      " 17  norm_snow_mm_total         158004 non-null  float64\n",
      " 18  distance_between           158004 non-null  float64\n",
      " 19  temp_avg_normal            158004 non-null  float64\n",
      " 20  temp_min_normal            158004 non-null  float64\n",
      " 21  temp_max_normal            158004 non-null  float64\n",
      " 22  temp_range_normal          158004 non-null  float64\n",
      " 23  prcp_mm_normal             158004 non-null  float64\n",
      " 24  tree_id                    158004 non-null  int64  \n",
      "dtypes: float64(15), int64(2), object(8)\n",
      "memory usage: 30.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#View our columns\n",
    "trees_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop our columns that are reference from climate dataset and the original condition column (which we used to create our target index feature)\n",
    "trees_df = trees_df.drop(columns=['nearest_station', 'station_id',\n",
    "       'station_name', 'lat_prcp', 'long_prcp', 'condition', 'planted_date','most_recent_observation','tree_id','long_trees','lat_trees','temp_min_normal','temp_max_normal','temp_range_normal']) #also drop some of the climate normals fields since they don't add anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['common_name', 'diameter_breast_height_CM', 'native', 'age_at_obs',\n",
       "       'condition_index', 'adj_reports', 'norm_prcp_mm_total',\n",
       "       'norm_snow_mm_total', 'distance_between', 'temp_avg_normal',\n",
       "       'prcp_mm_normal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Sample Dataset to Make Size More Manageable\n",
    "One model may not be too crazy, but running a gridsearch CV on hundreds of thousands of rows may be a bit much for me. I'll start with a sample of 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_sample = trees_df.sample(n=10000, replace=False, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Split Dependent and Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X = trees_sample.drop(columns=['condition_index'])\n",
    "y = trees_sample['condition_index']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train-Test Split\n",
    "We'll use an 80:20 split here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10) (8000,) (2000, 10) (2000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Impute Missing Values\n",
    "\n",
    "We will use the median for our age at observation and mode for common name.\n",
    "\n",
    "### 3.4.0 Establish Simple Imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name                   43\n",
       "diameter_breast_height_CM      0\n",
       "native                         0\n",
       "age_at_obs                   155\n",
       "adj_reports                    0\n",
       "norm_prcp_mm_total             0\n",
       "norm_snow_mm_total             0\n",
       "distance_between               0\n",
       "temp_avg_normal                0\n",
       "prcp_mm_normal                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Impute Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and transform\n",
    "X_train['age_at_obs'] = num_imputer.fit_transform(X_train[['age_at_obs']])\n",
    "X_train['common_name'] = cat_imputer.fit_transform(X_train[['common_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name                  0\n",
       "diameter_breast_height_CM    0\n",
       "native                       0\n",
       "age_at_obs                   0\n",
       "adj_reports                  0\n",
       "norm_prcp_mm_total           0\n",
       "norm_snow_mm_total           0\n",
       "distance_between             0\n",
       "temp_avg_normal              0\n",
       "prcp_mm_normal               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate no missing values\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Simple Feature Engineering\n",
    "\n",
    "Before running a first test model, I'll do some basic feature engineering. After testing on a single model we'll move into doing further tuning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Categorical Encoding\n",
    "\n",
    "We'll need to encode our categorical features. And for our tree names, we'll likely need to group together some of the less frequent options so we don't overwhelm our model with a crazy number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['common_name', 'native'], dtype='object')"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns = trees_df.select_dtypes(include='object').columns\n",
    "\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Red maple                  287\n",
       "Purpleleaf plum variety    237\n",
       "Norway maple               216\n",
       "Apple/crabapple            215\n",
       "(smooth) japanese maple    202\n",
       "                          ... \n",
       "Snow gum                     1\n",
       "Cascade snow cherry          1\n",
       "Javelin pear                 1\n",
       "Oceanspray                   1\n",
       "Almond tree                  1\n",
       "Name: common_name, Length: 485, dtype: int64"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view value_counts of common_name field\n",
    "X_train['common_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                       common_name\n",
       "(arnold) tulip tree         1              1\n",
       "Pacific yew                 1              1\n",
       "Patmore green ash           1              1\n",
       "Paw paw                     1              1\n",
       "Plane/sycamore              2              1\n",
       "                                          ..\n",
       "Empire ash                  2              1\n",
       "English elm                 1              1\n",
       "Eucalyptus/gum              2              1\n",
       "Eugene`s (carolina) poplar  2              1\n",
       "Zelkova                     2              1\n",
       "Length: 182, dtype: int64"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many of the 485 categories have less than 10 records?\n",
    "\n",
    "vc = pd.DataFrame(X_train['common_name'].value_counts())\n",
    "\n",
    "vc.reset_index(inplace=True)\n",
    "\n",
    "vc[vc['common_name'] < 3].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "introduced             116127\n",
       "no_info                 32616\n",
       "naturally_occurring      9261\n",
       "Name: native, dtype: int64"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view value_counts of common_name field\n",
    "trees_df['native'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1.0 Convert common_name Field to Group Names with < 100 Occurences\n",
    "\n",
    "This will limit the number of columns we have. We won't do thes ame for the native field. We'll do it by defining a function that can be utilized later as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_categories(df, col, n_limit):\n",
    "    \"\"\" Store categories in df[col] with counts less than the specified n and overwrite the corresponding values in the df with 'Other' \"\"\"\n",
    "    groups = df[col]\n",
    "    group_counts = groups.value_counts()\n",
    "    mask = groups.isin(group_counts[group_counts<n_limit].index)\n",
    "    df.loc[mask, col] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Red maple                  287\n",
       "Other                      257\n",
       "Purpleleaf plum variety    237\n",
       "Norway maple               216\n",
       "Apple/crabapple            215\n",
       "                          ... \n",
       "Japanese crabapple           3\n",
       "Princeton elm                3\n",
       "Stewartia                    3\n",
       "Autumn glory hawthorn        3\n",
       "Juniper                      3\n",
       "Name: common_name, Length: 304, dtype: int64"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use our group categories feature on our X_train set\n",
    "group_categories(X_train, 'common_name', 3)\n",
    "\n",
    "X_train['common_name'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 First Model\n",
    "\n",
    "Now that we've done some basic tuning, let's do some transforming with the feature engineering tools we fit and run a logistic regression model to see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_name</th>\n",
       "      <th>diameter_breast_height_CM</th>\n",
       "      <th>native</th>\n",
       "      <th>age_at_obs</th>\n",
       "      <th>adj_reports</th>\n",
       "      <th>norm_prcp_mm_total</th>\n",
       "      <th>norm_snow_mm_total</th>\n",
       "      <th>distance_between</th>\n",
       "      <th>temp_avg_normal</th>\n",
       "      <th>prcp_mm_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85168</th>\n",
       "      <td>Common serviceberry</td>\n",
       "      <td>7.62</td>\n",
       "      <td>introduced</td>\n",
       "      <td>3.652368</td>\n",
       "      <td>217</td>\n",
       "      <td>849.190323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.243978</td>\n",
       "      <td>53.2</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85613</th>\n",
       "      <td>missing</td>\n",
       "      <td>7.62</td>\n",
       "      <td>no_info</td>\n",
       "      <td>11.641581</td>\n",
       "      <td>217</td>\n",
       "      <td>849.190323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317906</td>\n",
       "      <td>53.2</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11471</th>\n",
       "      <td>Other</td>\n",
       "      <td>12.70</td>\n",
       "      <td>introduced</td>\n",
       "      <td>19.154397</td>\n",
       "      <td>347</td>\n",
       "      <td>1138.700000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.330051</td>\n",
       "      <td>53.8</td>\n",
       "      <td>926.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57576</th>\n",
       "      <td>American hornbeam</td>\n",
       "      <td>5.08</td>\n",
       "      <td>introduced</td>\n",
       "      <td>2.965153</td>\n",
       "      <td>224</td>\n",
       "      <td>1045.880645</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.434896</td>\n",
       "      <td>53.2</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130978</th>\n",
       "      <td>Pacific sunset maple</td>\n",
       "      <td>27.94</td>\n",
       "      <td>introduced</td>\n",
       "      <td>18.929889</td>\n",
       "      <td>19</td>\n",
       "      <td>1183.835484</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.953287</td>\n",
       "      <td>53.2</td>\n",
       "      <td>960.628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 common_name  diameter_breast_height_CM      native  \\\n",
       "85168    Common serviceberry                       7.62  introduced   \n",
       "85613                missing                       7.62     no_info   \n",
       "11471                  Other                      12.70  introduced   \n",
       "57576      American hornbeam                       5.08  introduced   \n",
       "130978  Pacific sunset maple                      27.94  introduced   \n",
       "\n",
       "        age_at_obs  adj_reports  norm_prcp_mm_total  norm_snow_mm_total  \\\n",
       "85168     3.652368          217          849.190323                 0.0   \n",
       "85613    11.641581          217          849.190323                 0.0   \n",
       "11471    19.154397          347         1138.700000                35.0   \n",
       "57576     2.965153          224         1045.880645                13.0   \n",
       "130978   18.929889           19         1183.835484                 5.0   \n",
       "\n",
       "        distance_between  temp_avg_normal  prcp_mm_normal  \n",
       "85168           1.243978             53.2         960.628  \n",
       "85613           0.317906             53.2         960.628  \n",
       "11471           1.330051             53.8         926.846  \n",
       "57576           3.434896             53.2         960.628  \n",
       "130978          1.953287             53.2         960.628  "
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Scalers and Transforms\n",
    "\n",
    "ss_scaler = StandardScaler()\n",
    "pow_trans = PowerTransformer()\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding some steps here -> My encoding is either encoding all values or keeping the specified ones. I want to fit and transform my categorical and then load them back into the main dataframe for a complete dataframe with scaled and encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_scaler, pow_trans, ohe\n",
    "#transform with our ss_scaler\n",
    "X_train[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','prcp_mm_normal']] = ss_scaler.fit_transform(X_train[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','prcp_mm_normal']])\n",
    "\n",
    "#transform with our pow_trans\n",
    "X_train[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']] = pow_trans.fit_transform(X_train[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']])\n",
    "\n",
    "#reset index to create clean join after encoding\n",
    "X_train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform with our categorical columns and create dataframes\n",
    "X_train_cn = ohe.fit_transform(X_train[['common_name']])\n",
    "cn_df = pd.DataFrame(X_train_cn, columns=ohe.categories_[0]) #indexing 0 here to grab only the column names\n",
    "\n",
    "X_train_nat = ohe.fit_transform(X_train[['native']])\n",
    "nat_df = pd.DataFrame(X_train_nat, columns=ohe.categories_[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10)\n",
      "(8000, 304)\n",
      "(8000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(cn_df.shape)\n",
    "print(nat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat these two dataframes back into X_train and create new dataframe, dropping original categorical fields\n",
    "X_train_transformed = pd.concat([X_train, cn_df, nat_df], axis=1,)\n",
    "\n",
    "#drop original categorical fields\n",
    "X_train_transformed.drop(columns=['common_name', 'native'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 315)"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.58\n"
     ]
    }
   ],
   "source": [
    "#Initiate and run logistic regression model\n",
    "\n",
    "logreg = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1)\n",
    "\n",
    "logreg.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(f'Accuracy on training data: {accuracy_score(logreg.predict(X_train_transformed), y_train):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       120\n",
      "         2.0       0.00      0.00      0.00       421\n",
      "         3.0       0.48      0.19      0.27      1921\n",
      "         4.0       0.59      0.94      0.73      4410\n",
      "         5.0       0.56      0.15      0.24      1128\n",
      "\n",
      "    accuracy                           0.58      8000\n",
      "   macro avg       0.33      0.25      0.25      8000\n",
      "weighted avg       0.52      0.58      0.50      8000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, logreg.predict(X_train_transformed)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decent accuracy, but it's because we're only predicting the most common values, which isn't suprising based on our imbalanced data. Let's work on addressing the imbalanced data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Work on Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 4410, 4410, 4410, 4410, 4410])"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use SMOTE to resample and balance our dataset\n",
    "sm = SMOTENC(random_state=42, categorical_features=[0,2])\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "np.bincount(y_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.0 Re-Run Model Using 'SMOTED' Data\n",
    "\n",
    "#### 3.7.0.0 Start by Re-Scaling and Encdoing and then Loading back to a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_scaler, pow_trans, ohe\n",
    "#transform with our ss_scaler\n",
    "X_res[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','prcp_mm_normal']] = ss_scaler.fit_transform(X_res[['age_at_obs','norm_prcp_mm_total', 'temp_avg_normal','prcp_mm_normal']])\n",
    "\n",
    "#transform with our pow_trans\n",
    "X_res[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']] = pow_trans.fit_transform(X_res[['diameter_breast_height_CM', 'norm_snow_mm_total','distance_between','adj_reports']])\n",
    "\n",
    "#reset index to create clean join after encoding\n",
    "X_res.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform with our categorical columns and create dataframes\n",
    "X_res_cn = ohe.fit_transform(X_res[['common_name']])\n",
    "cn_res_df = pd.DataFrame(X_res_cn, columns=ohe.categories_[0]) #indexing 0 here to grab only the column names\n",
    "\n",
    "X_res_nat = ohe.fit_transform(X_res[['native']])\n",
    "nat_res_df = pd.DataFrame(X_res_nat, columns=ohe.categories_[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22050, 10)\n",
      "(22050, 304)\n",
      "(22050, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_res.shape)\n",
    "print(cn_res_df.shape)\n",
    "print(nat_res_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050, 315)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat these two dataframes back into X_train and create new dataframe, dropping original categorical fields\n",
    "X_res_transformed = pd.concat([X_res, cn_res_df, nat_res_df], axis=1,)\n",
    "\n",
    "#drop original categorical fields\n",
    "X_res_transformed.drop(columns=['common_name', 'native'], inplace=True)\n",
    "\n",
    "X_res_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, max_iter=500, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, max_iter=500, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, max_iter=500, solver='liblinear')"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initiate and run logistic regression model\n",
    "\n",
    "logreg = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1)\n",
    "\n",
    "logreg.fit(X_res_transformed, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.49\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.57      0.80      0.67      4410\n",
      "         2.0       0.45      0.44      0.44      4410\n",
      "         3.0       0.41      0.27      0.33      4410\n",
      "         4.0       0.48      0.41      0.44      4410\n",
      "         5.0       0.48      0.55      0.51      4410\n",
      "\n",
      "    accuracy                           0.49     22050\n",
      "   macro avg       0.48      0.49      0.48     22050\n",
      "weighted avg       0.48      0.49      0.48     22050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on training data: {accuracy_score(logreg.predict(X_res_transformed), y_res):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_res, logreg.predict(X_res_transformed)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "Less overall accuracy, but this is a step in the right direction as our recall looks much better. With basically no hyperparamter tuning, we still have work to do.\n",
    "\n",
    "## 3.8 Tuning\n",
    "\n",
    "I tested out the pretty simple tuning but I'd actually like to do some different scaling depending on the feature in preperation for hyperparamter tuning. I'll do that now on my resampled dataframe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.1 Try Another Approach On Imbalanced Data\n",
    "\n",
    "Rather than using my resamples SMOTE dataframe, I want to try applying all of the other transformations the same, but this time on my initial 10,000 record sample using RepeatedStratifiedKFold cross validation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1.1 Define Our Cross-Validation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1.2 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model with our best params so far\n",
    "logreg2 = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8.1.3 Fit and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.58\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       120\n",
      "         2.0       0.00      0.00      0.00       421\n",
      "         3.0       0.48      0.19      0.27      1921\n",
      "         4.0       0.59      0.94      0.73      4410\n",
      "         5.0       0.56      0.15      0.24      1128\n",
      "\n",
      "    accuracy                           0.58      8000\n",
      "   macro avg       0.33      0.25      0.25      8000\n",
      "weighted avg       0.52      0.58      0.50      8000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "logreg2.fit(X_train_transformed, y_train)\n",
    "print(f'Accuracy on training data: {accuracy_score(logreg2.predict(X_train_transformed), y_train):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, logreg2.predict(X_train_transformed)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "Using the StratifiedKFold didn't give us as good of results as using SMOTE, so we'll go back to that method going forward."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Try Different Models\n",
    "\n",
    "The best we got with logistic regression was 47% accuracy. That leaves much to be desired, so let's try something other than this type of model. We'll use our X_res_scaled and y_res for consistency.\n",
    "\n",
    "### 3.9.0 Test Set Performance Comparison\n",
    "\n",
    "If we do some simple default setting comparison between KNeighbors, Decision Trees, and Random Forest, it could give us a good sense of where to focus our time going forward."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.0.0 Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list types of models to run\n",
    "models = {'logreg': LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1),\n",
    "          'knn': KNeighborsClassifier(),\n",
    "          'dec_tree': DecisionTreeClassifier(),\n",
    "          'rand_for': RandomForestClassifier(),\n",
    "          'ada': AdaBoostClassifier(),\n",
    "          'gradient': GradientBoostingClassifier()\n",
    "          }\n",
    "\n",
    "#create blank list to store results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through models, score and save\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True) #using KFold this time rather than setting up a whole GridSearch\n",
    "    cv_results = cross_val_score(model, X_res_transformed, y_res, cv=kf)\n",
    "    results.append(cv_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.0.1 Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "Our Random Forest looks to be the best option. Hopefully it's not ignoring all the minor classes. Let's explore this model futher.\n",
    "\n",
    "### 3.9.1 Random Forest Classifier\n",
    "\n",
    "This time I'll use RandomizedSearchCV to tune params. Source: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "#### 3.9.1.0 Create Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['log2', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "#list out our different params\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] #number of trees in the forest\n",
    "max_features = ['log2','sqrt'] #number of features to consider at each split\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)] #max levels in tree\n",
    "min_samples_split = [2,5,10] #min samples required to split a node\n",
    "min_samples_leaf = [1,2,4] #min samples at each leaf node\n",
    "bootstrap = [True, False] #sampling method using bootsrap or not\n",
    "\n",
    "#Create random grid\n",
    "rand_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(rand_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diameter_breast_height_CM</th>\n",
       "      <th>age_at_obs</th>\n",
       "      <th>adj_reports</th>\n",
       "      <th>norm_prcp_mm_total</th>\n",
       "      <th>norm_snow_mm_total</th>\n",
       "      <th>distance_between</th>\n",
       "      <th>temp_avg_normal</th>\n",
       "      <th>prcp_mm_normal</th>\n",
       "      <th>(american) arborvitae</th>\n",
       "      <th>(california) incense cedar</th>\n",
       "      <th>...</th>\n",
       "      <th>Willow oak</th>\n",
       "      <th>Wineleaf (spaethii sycamore)</th>\n",
       "      <th>Wintergold crabapple</th>\n",
       "      <th>Yellowwood</th>\n",
       "      <th>Yoshino cherry</th>\n",
       "      <th>Zumi crabapple</th>\n",
       "      <th>missing</th>\n",
       "      <th>introduced</th>\n",
       "      <th>naturally_occurring</th>\n",
       "      <th>no_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.719805</td>\n",
       "      <td>-1.840363</td>\n",
       "      <td>-0.648003</td>\n",
       "      <td>-2.231305</td>\n",
       "      <td>-0.984790</td>\n",
       "      <td>-0.102130</td>\n",
       "      <td>-0.750281</td>\n",
       "      <td>0.734990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.719805</td>\n",
       "      <td>-0.976624</td>\n",
       "      <td>-0.648003</td>\n",
       "      <td>-2.231305</td>\n",
       "      <td>-0.984790</td>\n",
       "      <td>-1.798127</td>\n",
       "      <td>-0.750281</td>\n",
       "      <td>0.734990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.156720</td>\n",
       "      <td>-0.164390</td>\n",
       "      <td>0.842330</td>\n",
       "      <td>1.065960</td>\n",
       "      <td>0.978043</td>\n",
       "      <td>0.009061</td>\n",
       "      <td>1.341023</td>\n",
       "      <td>-1.257013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.124883</td>\n",
       "      <td>-1.914660</td>\n",
       "      <td>-0.598560</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>0.638199</td>\n",
       "      <td>1.749781</td>\n",
       "      <td>-0.750281</td>\n",
       "      <td>0.734990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.816213</td>\n",
       "      <td>-0.188662</td>\n",
       "      <td>-1.500084</td>\n",
       "      <td>1.580015</td>\n",
       "      <td>0.253067</td>\n",
       "      <td>0.683313</td>\n",
       "      <td>-0.750281</td>\n",
       "      <td>0.734990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22045</th>\n",
       "      <td>1.392659</td>\n",
       "      <td>0.653267</td>\n",
       "      <td>-1.372165</td>\n",
       "      <td>0.432539</td>\n",
       "      <td>-0.984790</td>\n",
       "      <td>-0.682808</td>\n",
       "      <td>-0.750281</td>\n",
       "      <td>0.734990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22046</th>\n",
       "      <td>1.546000</td>\n",
       "      <td>0.774459</td>\n",
       "      <td>-0.500394</td>\n",
       "      <td>0.305456</td>\n",
       "      <td>-0.984790</td>\n",
       "      <td>0.440064</td>\n",
       "      <td>-0.750281</td>\n",
       "      <td>0.734990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22047</th>\n",
       "      <td>-1.124883</td>\n",
       "      <td>-1.347973</td>\n",
       "      <td>1.162368</td>\n",
       "      <td>-0.168622</td>\n",
       "      <td>1.091227</td>\n",
       "      <td>0.201770</td>\n",
       "      <td>1.341023</td>\n",
       "      <td>-1.257013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22048</th>\n",
       "      <td>0.963013</td>\n",
       "      <td>0.854333</td>\n",
       "      <td>0.842330</td>\n",
       "      <td>1.065960</td>\n",
       "      <td>0.978043</td>\n",
       "      <td>-0.638237</td>\n",
       "      <td>1.341023</td>\n",
       "      <td>-1.257013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22049</th>\n",
       "      <td>-1.124883</td>\n",
       "      <td>-1.564247</td>\n",
       "      <td>-1.534957</td>\n",
       "      <td>-0.265068</td>\n",
       "      <td>1.270086</td>\n",
       "      <td>1.231603</td>\n",
       "      <td>1.341023</td>\n",
       "      <td>-1.257013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22050 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       diameter_breast_height_CM  age_at_obs  adj_reports  norm_prcp_mm_total  \\\n",
       "0                      -0.719805   -1.840363    -0.648003           -2.231305   \n",
       "1                      -0.719805   -0.976624    -0.648003           -2.231305   \n",
       "2                      -0.156720   -0.164390     0.842330            1.065960   \n",
       "3                      -1.124883   -1.914660    -0.598560            0.008828   \n",
       "4                       0.816213   -0.188662    -1.500084            1.580015   \n",
       "...                          ...         ...          ...                 ...   \n",
       "22045                   1.392659    0.653267    -1.372165            0.432539   \n",
       "22046                   1.546000    0.774459    -0.500394            0.305456   \n",
       "22047                  -1.124883   -1.347973     1.162368           -0.168622   \n",
       "22048                   0.963013    0.854333     0.842330            1.065960   \n",
       "22049                  -1.124883   -1.564247    -1.534957           -0.265068   \n",
       "\n",
       "       norm_snow_mm_total  distance_between  temp_avg_normal  prcp_mm_normal  \\\n",
       "0               -0.984790         -0.102130        -0.750281        0.734990   \n",
       "1               -0.984790         -1.798127        -0.750281        0.734990   \n",
       "2                0.978043          0.009061         1.341023       -1.257013   \n",
       "3                0.638199          1.749781        -0.750281        0.734990   \n",
       "4                0.253067          0.683313        -0.750281        0.734990   \n",
       "...                   ...               ...              ...             ...   \n",
       "22045           -0.984790         -0.682808        -0.750281        0.734990   \n",
       "22046           -0.984790          0.440064        -0.750281        0.734990   \n",
       "22047            1.091227          0.201770         1.341023       -1.257013   \n",
       "22048            0.978043         -0.638237         1.341023       -1.257013   \n",
       "22049            1.270086          1.231603         1.341023       -1.257013   \n",
       "\n",
       "       (american) arborvitae  (california) incense cedar  ...  Willow oak  \\\n",
       "0                        0.0                         0.0  ...         0.0   \n",
       "1                        0.0                         0.0  ...         0.0   \n",
       "2                        0.0                         0.0  ...         0.0   \n",
       "3                        0.0                         0.0  ...         0.0   \n",
       "4                        0.0                         0.0  ...         0.0   \n",
       "...                      ...                         ...  ...         ...   \n",
       "22045                    0.0                         0.0  ...         0.0   \n",
       "22046                    0.0                         0.0  ...         0.0   \n",
       "22047                    0.0                         0.0  ...         0.0   \n",
       "22048                    0.0                         0.0  ...         0.0   \n",
       "22049                    0.0                         0.0  ...         0.0   \n",
       "\n",
       "       Wineleaf (spaethii sycamore)  Wintergold crabapple  Yellowwood  \\\n",
       "0                               0.0                   0.0         0.0   \n",
       "1                               0.0                   0.0         0.0   \n",
       "2                               0.0                   0.0         0.0   \n",
       "3                               0.0                   0.0         0.0   \n",
       "4                               0.0                   0.0         0.0   \n",
       "...                             ...                   ...         ...   \n",
       "22045                           0.0                   0.0         0.0   \n",
       "22046                           0.0                   0.0         0.0   \n",
       "22047                           0.0                   0.0         0.0   \n",
       "22048                           0.0                   0.0         0.0   \n",
       "22049                           0.0                   0.0         0.0   \n",
       "\n",
       "       Yoshino cherry  Zumi crabapple  missing  introduced  \\\n",
       "0                 0.0             0.0      0.0         1.0   \n",
       "1                 0.0             0.0      1.0         0.0   \n",
       "2                 0.0             0.0      0.0         1.0   \n",
       "3                 0.0             0.0      0.0         1.0   \n",
       "4                 0.0             0.0      0.0         1.0   \n",
       "...               ...             ...      ...         ...   \n",
       "22045             0.0             0.0      0.0         1.0   \n",
       "22046             0.0             0.0      0.0         1.0   \n",
       "22047             0.0             0.0      0.0         1.0   \n",
       "22048             0.0             0.0      0.0         1.0   \n",
       "22049             0.0             0.0      0.0         1.0   \n",
       "\n",
       "       naturally_occurring  no_info  \n",
       "0                      0.0      0.0  \n",
       "1                      0.0      1.0  \n",
       "2                      0.0      0.0  \n",
       "3                      0.0      0.0  \n",
       "4                      0.0      0.0  \n",
       "...                    ...      ...  \n",
       "22045                  0.0      0.0  \n",
       "22046                  0.0      0.0  \n",
       "22047                  0.0      0.0  \n",
       "22048                  0.0      0.0  \n",
       "22049                  0.0      0.0  \n",
       "\n",
       "[22050 rows x 315 columns]"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res_transformed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1.1 Fit with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=  36.2s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=  36.2s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=  36.3s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=  36.2s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=  36.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=  26.9s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=  26.8s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=  27.0s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=  26.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1600; total time=  26.2s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END bootstrap=True, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=  14.4s\n",
      "[CV] END bootstrap=True, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=  14.4s\n",
      "[CV] END bootstrap=True, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=  14.4s\n",
      "[CV] END bootstrap=True, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=  14.3s\n",
      "[CV] END bootstrap=True, max_depth=80, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=  14.6s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1200; total time=  27.5s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1200; total time=  27.7s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1200; total time=  27.7s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1200; total time=  27.7s\n",
      "[CV] END bootstrap=True, max_depth=70, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1200; total time=  28.0s\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time=  14.6s\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time=  14.7s\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time=  14.4s\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time=  14.4s\n",
      "[CV] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time=  14.3s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=  12.9s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=  12.9s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=  13.0s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=  12.8s\n",
      "[CV] END bootstrap=False, max_depth=70, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=  43.3s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=  44.1s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=  44.7s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=  44.1s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=  44.3s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=2000; total time=  27.5s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=2000; total time=  27.7s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=2000; total time=  27.8s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=2000; total time=  28.8s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=2000; total time=  29.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110],\n",
       "                                        'max_features': ['log2', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "#Random Search Cross-Val\n",
    "rf_rand = RandomizedSearchCV(estimator=rf, param_distributions=rand_grid, n_iter=10, cv=5, verbose=2, random_state=42) #sample 50 param settings, 5 fold cross-val, computation time display\n",
    "\n",
    "#fit the model on the non-scaled data\n",
    "rf_rand.fit(X_res_transformed, y_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1.2 Review Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 100,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = rf_rand.best_params_\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9.1.3 Fit Model Using Best Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.98\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00      4410\n",
      "         2.0       0.99      0.99      0.99      4410\n",
      "         3.0       0.97      0.97      0.97      4410\n",
      "         4.0       0.97      0.97      0.97      4410\n",
      "         5.0       0.98      0.99      0.99      4410\n",
      "\n",
      "    accuracy                           0.98     22050\n",
      "   macro avg       0.98      0.98      0.98     22050\n",
      "weighted avg       0.98      0.98      0.98     22050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run a fit with those params and view more details scoring\n",
    "\n",
    "#setup model\n",
    "rf_tuned = RandomForestClassifier(n_estimators=1800, min_samples_split=5, min_samples_leaf=1, max_features='log2', max_depth=100, bootstrap=True)\n",
    "\n",
    "#fit model\n",
    "rf_tuned.fit(X_res_transformed, y_res)\n",
    "\n",
    "#review scores\n",
    "print(f'Accuracy on training data: {accuracy_score(rf_tuned.predict(X_res_transformed), y_res):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_res, rf_tuned.predict(X_res_transformed)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "Siri, what's the definition of overfitting? K Thanks. I've got a bad feeling about the test set but let's see how it goes!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.2 Evaluate RF Model on Test Set\n",
    "\n",
    "The first thing we'll need to do is process our X_test using the same steps we did on our X_train.\n",
    "\n",
    "#### 3.9.2.0 Pre-Processing X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name                  category\n",
       "diameter_breast_height_CM     float64\n",
       "native                       category\n",
       "age_at_obs                    float64\n",
       "adj_reports                     int64\n",
       "norm_prcp_mm_total            float64\n",
       "norm_snow_mm_total            float64\n",
       "distance_between              float64\n",
       "temp_avg_normal               float64\n",
       "temp_min_normal               float64\n",
       "temp_max_normal               float64\n",
       "temp_range_normal             float64\n",
       "prcp_mm_normal                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Update object to categorical\n",
    "X_test['common_name'] = X_test.common_name.astype('category')\n",
    "X_test['native'] = X_test.native.astype('category')\n",
    "\n",
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/ds/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0, 1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#refit imputers\n",
    "num_imputer.fit(X_res[['age_at_obs']])\n",
    "cat_imputer.fit(X_res[['common_name']])\n",
    "\n",
    "#refit ohe on x_res\n",
    "ohe.fit(X_res[['common_name','native']])\n",
    "\n",
    "#Apply transformations from the steps we fitted earlier in the model\n",
    "X_test['age_at_obs'] = num_imputer.transform(X_test[['age_at_obs']])\n",
    "X_test['common_name'] = cat_imputer.transform(X_test[['common_name']])\n",
    "\n",
    "X_test_transformed = ohe.transform(X_test[['common_name','native']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x308 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1707 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.48\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.03      0.05      0.04        39\n",
      "         2.0       0.16      0.15      0.16        93\n",
      "         3.0       0.37      0.29      0.33       503\n",
      "         4.0       0.59      0.69      0.63      1091\n",
      "         5.0       0.27      0.17      0.21       274\n",
      "\n",
      "    accuracy                           0.48      2000\n",
      "   macro avg       0.28      0.27      0.27      2000\n",
      "weighted avg       0.46      0.48      0.46      2000\n",
      "\n",
      "----------------------------------------\n",
      "[[  2   7   3  25   2]\n",
      " [  2  14  29  46   2]\n",
      " [ 10  23 145 291  34]\n",
      " [ 41  32 176 753  89]\n",
      " [  9  11  36 171  47]]\n"
     ]
    }
   ],
   "source": [
    "#refit on unscaled data\n",
    "rf_tuned.fit(x_res_encoded, y_res)\n",
    "\n",
    "#predict\n",
    "y_pred = rf_tuned.predict(X_test_transformed)\n",
    "\n",
    "print(f'Accuracy on training data: {accuracy_score(y_pred, y_test):.2f}')\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('----------------------------------------')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\\\n",
    "\\\n",
    "As we'd expect from a lower training result, our test results aren't all that much better than a random guess if my math is correct. I will go ahead and export the model, but will continue to research and round back to see if there are any useful features that could be added or engineered to achieve better results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Save Model\n",
    "\n",
    "### 4.0.0 Define Saving Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions for saving model provided by Springboard Guided Capstone\n",
    "def _save_file(data, fpath):\n",
    "    valid_ftypes = ['.csv', '.pkl']\n",
    "    \n",
    "    assert (fpath[-4:] in valid_ftypes), \"Invalid file type.  Use '.csv' or '.pkl'\"\n",
    "\n",
    "    # Figure out what kind of file we're dealing with by name\n",
    "    if fpath[-3:] == 'csv':\n",
    "        data.to_csv(fpath, index=False)\n",
    "    elif fpath[-3:] == 'pkl':\n",
    "        with open(fpath, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "def save_file(data, fname, dname):\n",
    "    \"\"\"Save a datafile (data) to a specific location (dname) and filename (fname)\n",
    "    \n",
    "    Currently valid formats are limited to CSV or PKL.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(dname):\n",
    "        os.mkdir(dname)\n",
    "        print(f'Directory {dname} was created.')\n",
    "        \n",
    "    fpath = os.path.join(dname, fname)\n",
    "    \n",
    "    \n",
    "    if os.path.exists(fpath):\n",
    "        print(\"A file already exists with this name.\\n\")\n",
    "\n",
    "        yesno = None\n",
    "        while yesno != \"Y\" and yesno != \"N\":\n",
    "            yesno = input('Do you want to overwrite? (Y/N)').strip()[0].capitalize()\n",
    "            if yesno == \"Y\":\n",
    "                print(f'Writing file.  \"{fpath}\"')\n",
    "                _save_file(data, fpath)\n",
    "                break  # Not required\n",
    "            elif yesno == \"N\":\n",
    "                print('\\nPlease re-run this cell with a new filename.')\n",
    "                break  # Not required\n",
    "            else:\n",
    "                print('\\nUnknown input, please enter \"Y\" or \"N\".')\n",
    "\n",
    "    else:  # path does not exist, ok to save the file\n",
    "        print(f'Writing file.  \"{fpath}\"')\n",
    "        _save_file(data, fpath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.1 Identify Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf_rand.best_estimator_\n",
    "rf_model.version = '1.0'\n",
    "rf_model.pandas_version = pd.__version__\n",
    "rf_model.numpy_version = np.__version__\n",
    "rf_model.sklearn_version = sklearn_version\n",
    "rf_model.X_columns = [col for col in X_train.columns]\n",
    "rf_model.build_datetime = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file.  \"../models/trees_rf_model.pkl\"\n"
     ]
    }
   ],
   "source": [
    "#Save the model to the new /models folder\n",
    "modelpath = '../models/'\n",
    "save_file(rf_model, 'trees_rf_model.pkl', modelpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
